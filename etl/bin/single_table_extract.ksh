#! /bin/ksh
# Script generated by software licensed from Ab Initio.
# Use and disclosure are subject to Ab Initio confidentiality and license terms.
export AB_HOME;AB_HOME=${AB_HOME:-/usr/local/abinitio-V3-1-4}
export MPOWERHOME;MPOWERHOME="$AB_HOME"
export AB_COMPONENTS;AB_COMPONENTS="$AB_HOME"'/Projects/root/components'
export PATH
typeset _ab_uname=`uname`
case "$_ab_uname" in
Windows_* )
    PATH="$AB_HOME/bin;$PATH" ;;
CYGWIN_* )
    PATH="`cygpath "$AB_HOME"`/bin:/usr/local/bin:/usr/bin:/bin:$PATH" ;;
* )
    PATH="$AB_HOME/bin:$PATH" ;;
esac
unset ENV
export AB_REPORT;AB_REPORT=${AB_REPORT:-'monitor=300 processes scroll=true'}
unset GDE_EXECUTION

export AB_COMPATIBILITY;AB_COMPATIBILITY=3.1.4.4

# Deployed execution script for graph "single_table_extract", compiled at Thursday, September 11, 2014 10:09:53 using GDE version 3.0.3.1
export AB_JOB;AB_JOB=${AB_JOB_PREFIX:-""}single_table_extract
# Begin Ab Initio shell utility functions

: ${_ab_uname:=$(uname)}

function __AB_INVOKE_PROJECT
{
  typeset _AB_PROJECT_KSH="$1" ; shift
  typeset _AB_PROJECT_DIR="$1" ; shift
  typeset _AB_DEFINE_OR_EXECUTE="$1" ; shift
  typeset _AB_START_OR_END="$1" ; shift
  # Check that the project exists:
  if [ ! -r "$_AB_PROJECT_KSH" ] ; then
    print -r -u2 Warning: Cannot find common sandbox script: "$_AB_PROJECT_KSH"
    if [ ! -z "${_AB_CALLING_PROJECT:=}" ] ; then
      print -r -u2 Please check the common sandbox settings for the calling project: "$_AB_CALLING_PROJECT"
    fi
  fi
  if [ $# -gt 0 ] ; then
    . "$_AB_PROJECT_KSH" "$_AB_PROJECT_DIR" "$_AB_DEFINE_OR_EXECUTE" "$_AB_START_OR_END"  "$@"
  else
    . "$_AB_PROJECT_KSH" "$_AB_PROJECT_DIR" "$_AB_DEFINE_OR_EXECUTE" "$_AB_START_OR_END" 
  fi;
}

function __AB_DOTIT
{
  if [ $# -gt 0 ] ; then
    .  "$@"
  fi
}

function __AB_QUOTEIT {
  typeset queue q qq qed lotsaqs s trail
  q="'"
  qq='"'
  if [ X"$1" = X"" ] ; then
    print $q$q
    return
  fi
  lotsaqs=${q}${qq}${q}${qq}${q}
  if [ ${#1} -ge 10000 ]; then
    print -r -- "$1" | sed "s/$q/$lotsaqs/g; 1s/^/$q/; \$s/\$/$q/"
  else
    queue=${1%$q}
    if [ X"$queue" != X"$1" ] ; then
      trail="${qq}${q}${qq}" 
    else 
      trail=""
    fi
    oldIFS="$IFS"
    IFS=$q
    set -- $queue
    IFS="$oldIFS"
    print -rn "$q$1"
    shift
    for s; do
      print -rn "$lotsaqs$s"
    done
    print -r $q$trail
  fi
}

function __AB_dirname {
    case $_ab_uname in
    Windows_* | CYGWIN_* )
        typeset d='' p="$1"
        # Strip drive letter colon, if present, and put it into d.
        case $p in
        [A-Za-z]:* )
            d=${p%%:*}:
            p=${p#??}
            ;;
        esac
        # Remove trailing separators, though not the last character in the
        # pathname.
        while : true; do
            case $p in
            ?*[/\\] )
                p=${p%[/\\]} ;;
            * )
                break ;;
            esac
        done
        if [[ "$p" = ?*[/\\]* ]] ; then
            print -r -- "$d${p%[/\\]*}"
        elif [[ "$p" = [/\\]* ]] ; then
            print "$d/"
        else
            print "$d." 
        fi
        ;;
    * ) # Unix
        typeset p="$1"
        # Remove trailing separators, though not the last character in the
        # pathname.
        while : true; do
            case $p in
            ?*/ )
                p="${p%/}" ;;
            * )
                break ;;
            esac
        done
        case $p in
        ?*/* )
            print -r -- "${p%/*}" ;;
        /* )
            print / ;;
        * )
            print . ;;
        esac
        ;;
    esac
}

function __AB_concat_pathname {
    case $_ab_uname in
    Windows_* | CYGWIN_* )
        # Does not handle all cases of concatenating partially absolute
        # pathnames, those with only one of a drive letter or an initial
        # separator.
        case $2 in
        [/\\]* | [A-Za-z]:* )
            print -r -- "$2"
            ;;
        * )
            case $1 in
            # Assume that empty string means ".".  Avoid adding a
            # redundant separator.
            '' | *[/\\] )
                print -r -- "$1$2" ;;
            * )
                print -r -- "$1/$2" ;;
            esac
            ;;
        esac
        ;;
    * ) # Unix
        case $2 in
        /* )
            print -r -- "$2"
            ;;
        * )
            case $1 in
            # Assume that empty string means ".".  Avoid adding a
            # redundant separator.
            '' | */ )
                print -r -- "$1$2" ;;
            * )
                print -r -- "$1/$2" ;;
            esac
            ;;
        esac
        ;;
    esac
}

function __AB_COND {
if [ X"$1" = X0  -o X"$1" = Xfalse -o X"$1" = XFalse -o X"$1" = XF -o X"$1" = Xf ] ; then
  print "0"
else
  print "1"
fi
}

# End Ab Initio shell utility functions
export AB_GRAPH_NAME;AB_GRAPH_NAME=single_table_extract

# Host Setup Commands:
. /dw/etl/mstr_cfg/etlenv.setup
_AB_PROXY_DIR=single_table_extract-ProxyDir-$$
rm -rf "${_AB_PROXY_DIR}"
mkdir "${_AB_PROXY_DIR}"
print -r -- "" > "${_AB_PROXY_DIR}"'/GDE-Parameters'
function __AB_CLEANUP_PROXY_FILES
{
   rm -rf "${_AB_PROXY_DIR}"
   rm -rf "${AB_EXTERNAL_PROXY_DIR}"
   return
}
trap '__AB_CLEANUP_PROXY_FILES' EXIT
# Work around pdksh bug: the EXIT handler is not executed upon a signal.
trap '_AB_status=$?; __AB_CLEANUP_PROXY_FILES; exit $_AB_status' HUP INT QUIT TERM
if [ $# -gt 0 -a X"$1" = X"-help" ]; then
print -r -- 'Usage: single_table_extract.ksh <ETL_ID> <FILE_ID> <AB_IDB_CONFIG> <SOURCE_NAME_NOT_USED> <DATA_FILENAME_TMP> [-DML_FILENAME <DML_FILENAME>] -UOW_FROM <UOW_FROM> -UOW_TO <UOW_TO> -PARAM1 <PARAM1> -PARAM2 <PARAM2> -PARAM3 <PARAM3> -PARAM4 <PARAM4>'
exit 1
fi

# Command Line Processing
function _AB_PARSE_ARGUMENTS {
   unset ETL_ID
   unset FILE_ID
   unset AB_IDB_CONFIG
   unset SOURCE_NAME_NOT_USED
   unset DATA_FILENAME_TMP
   unset DML_FILENAME
   unset UOW_FROM
   unset UOW_TO
   unset PARAM1
   unset PARAM2
   unset PARAM3
   unset PARAM4
   _ab_index_var=0
   if [ $# -gt 0 ]; then
      export ETL_ID;      ETL_ID="${1}"
      let _ab_index_var=_ab_index_var+1
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      shift
   fi
   if [ $# -gt 0 ]; then
      export FILE_ID;      FILE_ID="${1}"
      let _ab_index_var=_ab_index_var+1
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      shift
   fi
   if [ $# -gt 0 ]; then
      export AB_IDB_CONFIG;      AB_IDB_CONFIG="${1}"
      let _ab_index_var=_ab_index_var+1
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      shift
   fi
   if [ $# -gt 0 ]; then
      export SOURCE_NAME_NOT_USED;      SOURCE_NAME_NOT_USED="${1}"
      let _ab_index_var=_ab_index_var+1
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      shift
   fi
   if [ $# -gt 0 ]; then
      export DATA_FILENAME_TMP;      DATA_FILENAME_TMP="${1}"
      let _ab_index_var=_ab_index_var+1
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      shift
   fi
   while [ $# -gt 0 ]; do
   _ab_kwd="${1}"
   let _ab_index_var=_ab_index_var+1
   shift
   case ${_ab_kwd} in
   # DML_FILENAME - optional dml file name - used to override the default dml file
     -DML_FILENAME )
      export DML_FILENAME;      DML_FILENAME="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
   # UOW_FROM - Unit of Work
     -UOW_FROM )
      export UOW_FROM;      UOW_FROM="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
   # UOW_TO - Next Unit of Work
     -UOW_TO )
      export UOW_TO;      UOW_TO="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
   # PARAM1 - shell interpretation
     -PARAM1 )
      export PARAM1;      PARAM1="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
   # PARAM2 - shell interpretation
     -PARAM2 )
      export PARAM2;      PARAM2="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
   # PARAM3 - shell interpretation
     -PARAM3 )
      export PARAM3;      PARAM3="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
   # PARAM4 - shell interpretation
     -PARAM4 )
      export PARAM4;      PARAM4="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
   # CNDTL_EXTRACT_COMPRESS_LEVEL - fILE COMPRESSION LEVEL (0-9)
     -CNDTL_EXTRACT_COMPRESS_LEVEL )
      CNDTL_EXTRACT_COMPRESS_LEVEL="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -CNDTL_EXTRACT_COMPRESS )
      CNDTL_EXTRACT_COMPRESS="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -CHECK_SQL_FILE )
      CHECK_SQL_FILE="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -INPUT_TABLE_SEL )
      export INPUT_TABLE_SEL;      INPUT_TABLE_SEL="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -AB_IDB_MAX_ORACLE_LOB_SIZE )
      AB_IDB_MAX_ORACLE_LOB_SIZE="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -TD_USERNAME )
      export TD_USERNAME;      TD_USERNAME="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -TD_PASSWORD )
      export TD_PASSWORD;      TD_PASSWORD="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -OUTPUT_DML )
      export OUTPUT_DML;      OUTPUT_DML="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -REFORMAT_TRANS_FILE )
      export REFORMAT_TRANS_FILE;      REFORMAT_TRANS_FILE="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -QUERY_BAND_STRING )
      export QUERY_BAND_STRING;      QUERY_BAND_STRING="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
   * )
      if [ X"${_AB_USED_ARGUMENTS[_ab_index_var]}" != X1 ]; then
         print -r -- 'Unexpected command line argument found: '"${_ab_kwd}"
         print -r -- 'Usage: single_table_extract.ksh <ETL_ID> <FILE_ID> <AB_IDB_CONFIG> <SOURCE_NAME_NOT_USED> <DATA_FILENAME_TMP> [-DML_FILENAME <DML_FILENAME>] -UOW_FROM <UOW_FROM> -UOW_TO <UOW_TO> -PARAM1 <PARAM1> -PARAM2 <PARAM2> -PARAM3 <PARAM3> -PARAM4 <PARAM4>'
         exit 1
      fi
   esac
   done
}
if [ $# -gt 0 ]; then
   _AB_PARSE_ARGUMENTS "$@"
else
   _AB_PARSE_ARGUMENTS
fi

if [ X"${ETL_ID:-}" = X"" ]; then
   print -r -- 'Required parameter ETL_ID undefined'
   print -r -- 'Usage: single_table_extract.ksh <ETL_ID> <FILE_ID> <AB_IDB_CONFIG> <SOURCE_NAME_NOT_USED> <DATA_FILENAME_TMP> [-DML_FILENAME <DML_FILENAME>] -UOW_FROM <UOW_FROM> -UOW_TO <UOW_TO> -PARAM1 <PARAM1> -PARAM2 <PARAM2> -PARAM3 <PARAM3> -PARAM4 <PARAM4>'
   exit 1
fi
export FILE_ID;FILE_ID=${FILE_ID:-1}

if [ X"${AB_IDB_CONFIG:-}" = X"" ]; then
   print -r -- 'Required parameter AB_IDB_CONFIG undefined'
   print -r -- 'Usage: single_table_extract.ksh <ETL_ID> <FILE_ID> <AB_IDB_CONFIG> <SOURCE_NAME_NOT_USED> <DATA_FILENAME_TMP> [-DML_FILENAME <DML_FILENAME>] -UOW_FROM <UOW_FROM> -UOW_TO <UOW_TO> -PARAM1 <PARAM1> -PARAM2 <PARAM2> -PARAM3 <PARAM3> -PARAM4 <PARAM4>'
   exit 1
fi

if [ X"${SOURCE_NAME_NOT_USED:-}" = X"" ]; then
   print -r -- 'Required parameter SOURCE_NAME_NOT_USED undefined'
   print -r -- 'Usage: single_table_extract.ksh <ETL_ID> <FILE_ID> <AB_IDB_CONFIG> <SOURCE_NAME_NOT_USED> <DATA_FILENAME_TMP> [-DML_FILENAME <DML_FILENAME>] -UOW_FROM <UOW_FROM> -UOW_TO <UOW_TO> -PARAM1 <PARAM1> -PARAM2 <PARAM2> -PARAM3 <PARAM3> -PARAM4 <PARAM4>'
   exit 1
fi
export DATA_FILENAME_TMP;DATA_FILENAME_TMP=${DATA_FILENAME_TMP:-"$ETL_ID"'.'"$FILE_ID"'.dat'}
export DML_FILENAME;DML_FILENAME=${DML_FILENAME:-"$ETL_ID"'.read.dml'}
export UOW_FROM;UOW_FROM=${UOW_FROM:-""}
export UOW_TO;UOW_TO=${UOW_TO:-""}
export PARAM1;PARAM1=${PARAM1:-""}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter PARAM1 of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export PARAM2;PARAM2=${PARAM2:-""}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter PARAM2 of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export PARAM3;PARAM3=${PARAM3:-""}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter PARAM3 of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export PARAM4;PARAM4=${PARAM4:-""}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter PARAM4 of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export JOB_ENV;JOB_ENV=extract
export UOW_DATE;UOW_DATE='$(print '"$UOW_TO"' | cut -c1-8)'
export ETL_CFG_FILE;ETL_CFG_FILE="$DW_CFG"'/'"$ETL_ID"'.cfg'
export SUBJECT_AREA;SUBJECT_AREA=${ETL_ID%%.*}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter SUBJECT_AREA of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export TABLE_ID;TABLE_ID=${ETL_ID##*.}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter TABLE_ID of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export AB_JOB;AB_JOB=$(if [ $ETL_ENV ]
then
   print $AB_JOB.$ETL_ID.$FILE_ID.$ETL_ENV.$JOB_ENV
else
   print $AB_JOB.$ETL_ID.$FILE_ID.$JOB_ENV
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter AB_JOB of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export EXTRACT_TYPE;EXTRACT_TYPE=$(if [[ ${AB_IDB_CONFIG%%_*} = "teradata" ]]
then
   print T
elif [[ ${AB_IDB_CONFIG%%_*} = "oracle" ]]
then
   print O
elif [[ ${AB_IDB_CONFIG%%_*} = @("sqlserver"|"mssql") ]]
then
   print S
elif [[ ${AB_IDB_CONFIG%%_*} = "mysql" ]]
then
   print M
elif [[ ${AB_IDB_CONFIG%%_*} = "odbc" ]]
then
   print G
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter EXTRACT_TYPE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export TNS_NAME;TNS_NAME=$(if [[ $EXTRACT_TYPE = "O" ]]
then
   grep "^db_name\>" $DW_DBC/$AB_IDB_CONFIG | read A TNS_NAME_TMP
   print ${TNS_NAME_TMP#@}
elif [[ $EXTRACT_TYPE = "S" || $EXTRACT_TYPE = "M" || $EXTRACT_TYPE = "G" ]]
then
   grep "^odbc_data_source_name\>" $DW_DBC/$AB_IDB_CONFIG | read A TNS_NAME_TMP
   print ${TNS_NAME_TMP}
elif [[ $EXTRACT_TYPE = "T" ]]
then
   grep "^db_name\>" $DW_DBC/$AB_IDB_CONFIG | read A TNS_NAME_VARA_TMP
   TNS_NAME_VARA_TMP2=${TNS_NAME_VARA_TMP#*\{}
   TD_TNS_NAME_TMP=${TNS_NAME_VARA_TMP2%\}*}
   grep "^$TD_TNS_NAME_TMP\>" $DW_CFG/tnsnames.td | read TD_TNS_NAME_TMP TD_TNS_NAME_TMP2

   if [[ $? = 0 ]]
   then
     print ${TD_TNS_NAME_TMP}
   else
     print 0
   fi
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter TNS_NAME of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export ORA_USERNAME;ORA_USERNAME=$(if [[ $EXTRACT_TYPE = "O" ]]
then
   grep "^$TNS_NAME\>" $DW_LOGINS/ora_logins.dat | read TNS_NAME ORA_USER ORA_PASS
   print $ORA_USER
else
   print 0
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter ORA_USERNAME of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export ORA_PASSWORD;ORA_PASSWORD=$(if [[ $EXTRACT_TYPE = "O" ]]
then
   grep "^$TNS_NAME\>" $DW_LOGINS/ora_logins.dat | read TNS_NAME ORA_USER ORA_PASS
   print $ORA_PASS
else
   print 0
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter ORA_PASSWORD of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export MSSQL_USERNAME;MSSQL_USERNAME=$(if [[ $EXTRACT_TYPE = "S" ]]
then
   grep "^$TNS_NAME\>" $DW_LOGINS/mssql_logins.dat | read TNS_NAME MSSQL_USER MSSQL_PASS
   print $MSSQL_USER
else
   print 0
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter MSSQL_USERNAME of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export MSSQL_PASSWORD;MSSQL_PASSWORD=$(if [[ $EXTRACT_TYPE = "S" ]]
then
   grep "^$TNS_NAME\>" $DW_LOGINS/mssql_logins.dat | read TNS_NAME MSSQL_USER MSSQL_PASS
   print $MSSQL_PASS
else
   print 0
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter MSSQL_PASSWORD of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export MYSQL_USERNAME;MYSQL_USERNAME=$(if [[ $EXTRACT_TYPE = "M" ]]
then
   grep "^$TNS_NAME\>" $DW_LOGINS/mysql_logins.dat | read TNS_NAME MYSQL_USER MYSQL_PASS
   print $MYSQL_USER
else
   print 0
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter MYSQL_USERNAME of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export MYSQL_PASSWORD;MYSQL_PASSWORD=$(if [[ $EXTRACT_TYPE = "M" ]]
then
   grep "^$TNS_NAME\>" $DW_LOGINS/mysql_logins.dat | read TNS_NAME MYSQL_USER MYSQL_PASS
   print $MYSQL_PASS
else
   print 0
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter MYSQL_PASSWORD of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export FEXP_SLEEP;FEXP_SLEEP=$(if [[ $EXTRACT_TYPE = "T" ]]
then
   print $(grep "^FEXP_SLEEP\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE)
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter FEXP_SLEEP of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export FEXP_TENACITY;FEXP_TENACITY=$(if [[ $EXTRACT_TYPE = "T" ]]
then
   print $(grep "^FEXP_TENACITY\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE)
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter FEXP_TENACITY of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export FEXP_SESSION_MAX_FIRST;FEXP_SESSION_MAX_FIRST=$(if [[ $EXTRACT_TYPE = "T" ]]


then


   grep "^FEXP_SESSION_MAX_FIRST\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT;

   if [[ $VALUE -ge 24 ]]
   then
     eval print $VALUE
   else
     print 24
   fi


fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter FEXP_SESSION_MAX_FIRST of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export FEXP_SESSION_MIN_SECOND;FEXP_SESSION_MIN_SECOND=$(if [[ $EXTRACT_TYPE = "T" ]]


then


   grep "^FEXP_SESSION_MIN_SECOND\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; 
   if [[ $VALUE -ge 24 ]]
then
   eval print $VALUE
else
   print 24
fi



fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter FEXP_SESSION_MIN_SECOND of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export TD_USE_API;TD_USE_API=$(if [[ $EXTRACT_TYPE = "T" ]]
then
   print $(grep "^TD_USE_API\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print ${VALUE:-0})
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter TD_USE_API of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export MSSQL_HOST;MSSQL_HOST=$(if [[ $EXTRACT_TYPE = "S" ]]
then
   print $(grep "^HOST_NAME\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE)
else
   print ${servername}
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter MSSQL_HOST of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export AB_TCP_PORT_LEAST;AB_TCP_PORT_LEAST=$(if [[ $EXTRACT_TYPE = "S" ]]
then
   print $(grep "^AB_TCP_PORT_LEAST\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE)
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter AB_TCP_PORT_LEAST of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export AB_CHECK_HETERO_DATA_TYPES_;AB_CHECK_HETERO_DATA_TYPES_=$(if [[ $EXTRACT_TYPE = "S" ]]
then
   print $(grep "^AB_CHECK_HETERO_DATA_TYPES\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE)
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter AB_CHECK_HETERO_DATA_TYPES_ of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export AB_TCP_PORT_MOST;AB_TCP_PORT_MOST=$(if [[ $EXTRACT_TYPE = "S" ]]
then
   print $(grep "^AB_TCP_PORT_MOST\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE)
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter AB_TCP_PORT_MOST of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export DW_SA_ARC;DW_SA_ARC="$DW_ARC"'/'"$JOB_ENV"'/'"$SUBJECT_AREA"
export DW_SA_DAT;DW_SA_DAT="$DW_DAT"'/'"$JOB_ENV"'/'"$SUBJECT_AREA"
export DW_SA_LOG;DW_SA_LOG=${DW_SA_LOG:-$DW_LOG/$JOB_ENV/$SUBJECT_AREA}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter DW_SA_LOG of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export DW_SA_TMP;DW_SA_TMP="$DW_TMP"'/'"$JOB_ENV"'/'"$SUBJECT_AREA"
export FILE_DATETIME;FILE_DATETIME=${CURR_DATETIME:-$(date '+%Y%m%d-%H%M%S')}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter FILE_DATETIME of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export BATCH_SEQ_NUM;BATCH_SEQ_NUM=$(( $(<$DW_SA_DAT/$TABLE_ID.extract.batch_seq_num.dat) + 1))
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter BATCH_SEQ_NUM of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
CNDTL_EXTRACT_COMPRESS_LEVEL=$(grep "^CNDTL_EXTRACT_COMPRESS_LEVEL\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print ${VALUE:-""})
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CNDTL_EXTRACT_COMPRESS_LEVEL of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
CNDTL_EXTRACT_COMPRESS=$(grep "^CNDTL_EXTRACT_COMPRESS\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT;  print ${VALUE:-0})
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CNDTL_EXTRACT_COMPRESS of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export DATA_FILENAME;DATA_FILENAME=$(if [[ -n $UOW_TO ]]
  then
     if [[ $DATA_FILENAME_TMP = "N" ]]
     then
        print $(grep "^DATA_FILENAME\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE)
     else
        eval print $DATA_FILENAME_TMP
     fi
  else
     if [[ $DATA_FILENAME_TMP = "N" ]]
     then
        print $(grep "^DATA_FILENAME\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE.$BATCH_SEQ_NUM)
     else
        eval print $DATA_FILENAME_TMP.$BATCH_SEQ_NUM
     fi
  fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter DATA_FILENAME of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export IN_DIR;IN_DIR=${IN_DIR:-$(grep "^IN_DIR\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE/$JOB_ENV/$SUBJECT_AREA)}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter IN_DIR of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export WRK_DIR;WRK_DIR=$(grep "^WRK_DIR\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE/$SUBJECT_AREA)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter WRK_DIR of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export LAST_EXTRACT_TYPE;LAST_EXTRACT_TYPE=$(grep "^LAST_EXTRACT_TYPE\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print $VALUE)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter LAST_EXTRACT_TYPE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export CNDTL_LAST_EXTRACT_ROLLUP;CNDTL_LAST_EXTRACT_ROLLUP=$(if [[ $LAST_EXTRACT_TYPE = "R" ]]; then print 1; else print 0; fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CNDTL_LAST_EXTRACT_ROLLUP of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export CNDTL_LAST_EXTRACT_VARIABLE;CNDTL_LAST_EXTRACT_VARIABLE=$(if [[ $LAST_EXTRACT_TYPE = "V" ]]; then print 1; else print 0; fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CNDTL_LAST_EXTRACT_VARIABLE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export LAST_EXTRACT_VALUE_FILE;LAST_EXTRACT_VALUE_FILE=$(if [[ $LAST_EXTRACT_TYPE != @("N"|"U") ]]
  then
     print $DW_SA_DAT/$TABLE_ID.$FILE_ID.last_extract_value.dat
  else
     print a
  fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter LAST_EXTRACT_VALUE_FILE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export UOW_FROM_REFORMAT_CODE;UOW_FROM_REFORMAT_CODE=$(if [[ $LAST_EXTRACT_TYPE == "U" ]]
  then
   grep "^UOW_FROM_REFORMAT_CODE\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print ${VALUE:-0}
  fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter UOW_FROM_REFORMAT_CODE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export UOW_TO_REFORMAT_CODE;UOW_TO_REFORMAT_CODE=$(if [[ $LAST_EXTRACT_TYPE == "U" ]]
  then
   grep "^UOW_TO_REFORMAT_CODE\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print ${VALUE:-0}
  fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter UOW_TO_REFORMAT_CODE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export FROM_EXTRACT_VALUE;FROM_EXTRACT_VALUE=$(if [[ $LAST_EXTRACT_TYPE == @("V"|"R") ]]
  then
     print $(<$LAST_EXTRACT_VALUE_FILE)
  elif [[ $LAST_EXTRACT_TYPE == "U" ]]
  then
     print $(eval $DW_MASTER_EXE/dw_infra.reformat_timestamp.ksh $UOW_FROM $UOW_FROM_REFORMAT_CODE)
  fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter FROM_EXTRACT_VALUE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export TO_EXTRACT_VALUE_FUNCTION;TO_EXTRACT_VALUE_FUNCTION=$(if [[ $LAST_EXTRACT_TYPE = "V" ]]
  then
     print $(grep "^TO_EXTRACT_VALUE_FUNCTION\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE)
  fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter TO_EXTRACT_VALUE_FUNCTION of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export TO_EXTRACT_VALUE;TO_EXTRACT_VALUE=$(if [[ $LAST_EXTRACT_TYPE == "V" ]]
  then
     print $($TO_EXTRACT_VALUE_FUNCTION)
  elif [[ $LAST_EXTRACT_TYPE == "U" ]]
  then
     print $(eval $DW_MASTER_EXE/dw_infra.reformat_timestamp.ksh $UOW_TO $UOW_TO_REFORMAT_CODE)
  fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter TO_EXTRACT_VALUE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export CREATE_TMP_SQL_FILE;CREATE_TMP_SQL_FILE=$(set -e
  print "cat <<EOF" > $DW_SA_TMP/$TABLE_ID.ex.$FILE_ID.sel.sql.tmp
  cat $DW_SQL/$ETL_ID.sel.sql >> $DW_SA_TMP/$TABLE_ID.ex.$FILE_ID.sel.sql.tmp
  print -- "--END-OF-SQL" >> $DW_SA_TMP/$TABLE_ID.ex.$FILE_ID.sel.sql.tmp
  print "\nEOF" >> $DW_SA_TMP/$TABLE_ID.ex.$FILE_ID.sel.sql.tmp
  set +e)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CREATE_TMP_SQL_FILE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export INPUT_TABLE_SEL1;INPUT_TABLE_SEL1=$(. $DW_SA_TMP/$TABLE_ID.ex.$FILE_ID.sel.sql.tmp)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter INPUT_TABLE_SEL1 of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
CHECK_SQL_FILE=$(
set +e
print $INPUT_TABLE_SEL1 | grep "END-OF-SQL"
err=$?
set -e

if [ $err -eq 1 ]
then
        print "SQL File is not integrated : $DW_SA_TMP/$TABLE_ID.ex.$FILE_ID.sel.sql.tmp" >&2
        exit 1
fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CHECK_SQL_FILE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export INPUT_TABLE_SEL;INPUT_TABLE_SEL=${INPUT_TABLE_SEL1%%--END-OF-SQL*}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter INPUT_TABLE_SEL of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export USE_ABLOCAL;USE_ABLOCAL=$(grep "^USE_ABLOCAL\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print $VALUE)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter USE_ABLOCAL of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export CREATE_TMP_ABLOCAL_FILE;CREATE_TMP_ABLOCAL_FILE=$(if [[ $USE_ABLOCAL = "1" ]]
  then
    set -e
    print "cat <<EOF" > $DW_SA_TMP/$TABLE_ID.ex.$FILE_ID.sel.abl.tmp
    cat $DW_SQL/$ETL_ID.sel.abl >> $DW_SA_TMP/$TABLE_ID.ex.$FILE_ID.sel.abl.tmp
    print "EOF" >> $DW_SA_TMP/$TABLE_ID.ex.$FILE_ID.sel.abl.tmp
    set +e
  fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CREATE_TMP_ABLOCAL_FILE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export ABLOCAL;ABLOCAL=$(if [[ $USE_ABLOCAL = "1" ]]
  then
    . $DW_SA_TMP/$TABLE_ID.ex.$FILE_ID.sel.abl.tmp
  fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter ABLOCAL of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export INPUT_DML;INPUT_DML="$DW_DML"'/'"$DML_FILENAME"
export UOW_APPEND;UOW_APPEND=$(if [[ $LAST_EXTRACT_TYPE == "U" ]]
  then
    print ".$UOW_TO"
  else
    print ""
  fi
 )
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter UOW_APPEND of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export ORA_MAX_KB;ORA_MAX_KB=$(if [[ $EXTRACT_TYPE = "O" ]]
then
   grep "^ORA_MAX_KB\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT
   print $VALUE
else
   print 0
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter ORA_MAX_KB of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export EXTRACT_LOG_FILE;EXTRACT_LOG_FILE="$DW_SA_LOG"'/'"$TABLE_ID"'.ex.'"$FILE_ID"'.input_table_extract'"$UOW_APPEND"'.'"$FILE_DATETIME"'.log'
export OUTPUT_FILE;OUTPUT_FILE=$(if [ $CNDTL_EXTRACT_COMPRESS != 1 ]
  then
    eval print $IN_DIR/$DATA_FILENAME
  else
    eval print $IN_DIR/$DATA_FILENAME.gz
  fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter OUTPUT_FILE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export ROLLUP_FIELD;ROLLUP_FIELD=$(grep "^ROLLUP_FIELD\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print $VALUE)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter ROLLUP_FIELD of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export EXTEND_ROWSET_SIZE_USE;EXTEND_ROWSET_SIZE_USE=$(grep "^EXTEND_ROWSET_SIZE_USE\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print $VALUE)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter EXTEND_ROWSET_SIZE_USE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export ROWSET_SIZE;ROWSET_SIZE=$(if [[ $EXTEND_ROWSET_SIZE_USE = "1" ]]
  then
     print $(grep "^ROWSET_SIZE\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print $VALUE)
  else
     print 1000
  fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter ROWSET_SIZE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export AB_IDB_EXTEND_ROWSET_SIZE_USE;AB_IDB_EXTEND_ROWSET_SIZE_USE=$(if [[ $EXTEND_ROWSET_SIZE_USE = "1" ]]
  then
     print True
  else
     print False
  fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter AB_IDB_EXTEND_ROWSET_SIZE_USE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
AB_IDB_MAX_ORACLE_LOB_SIZE=$(grep "^MAX_ORACLE_LOB_SIZE_OVRD\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print ${VALUE:-100000})
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter AB_IDB_MAX_ORACLE_LOB_SIZE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export RECORD_COUNT_FILE;RECORD_COUNT_FILE="$DW_SA_TMP"'/'"$TABLE_ID"'.ex.'"$FILE_ID"'.record_count.dat'
export TD_USERNAME;TD_USERNAME=$(if [[ $EXTRACT_TYPE = "T" ]]
then
   grep "^$TNS_NAME[    ][    ]*$SUBJECT_AREA\>" $DW_LOGINS/teradata_logins.dat | read TNS_NAME TNS_SUBJECT_AREA TD_USER TD_PASS
   if [[ $? = 0 ]] 
   then 
     print $TD_USER
   else
     print $TD_USERNAME
   fi
else
   print 0
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter TD_USERNAME of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export TD_PASSWORD;TD_PASSWORD=$(if [[ $EXTRACT_TYPE = "T" ]]
then
   grep "^$TNS_NAME[    ][      ]*$SUBJECT_AREA\>" $DW_LOGINS/teradata_logins.dat | read TNS_NAME TNS_SUBJECT_AREA TD_USER TD_PASS
   if [[ $? = 0 ]] 
   then 
     print $TD_PASS
   else
     print $TD_PASSWORD
   fi
else
   print 0
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter TD_PASSWORD of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export ODBC_USERNAME;ODBC_USERNAME=$(if [[ $EXTRACT_TYPE = "G" ]]
then
   grep "^$TNS_NAME\>" $DW_LOGINS/odbc_logins.dat | read TNS_NAME ODBC_USER ODBC_PASS
   print $ODBC_USER
else
   print 0
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter ODBC_USERNAME of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export ODBC_PASSWORD;ODBC_PASSWORD=$(if [[ $EXTRACT_TYPE = "G" ]]
then
   grep "^$TNS_NAME\>" $DW_LOGINS/odbc_logins.dat | read TNS_NAME ODBC_USER ODBC_PASS
   print $ODBC_PASS
else
   print 0
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter ODBC_PASSWORD of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export TABLE_ID21;TABLE_ID21=${TABLE_ID%${TABLE_ID#?????????????????????}}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter TABLE_ID21 of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export FEXP_LOGTAB;FEXP_LOGTAB=${TABLE_ID21:-$TABLE_ID}_$$_L
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter FEXP_LOGTAB of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export FEXP_LOGFILE;FEXP_LOGFILE=$(if [[ $EXTRACT_TYPE = "T" ]]
then
   print $(grep "^FEXP_LOGFILE\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print ${VALUE:-"$DW_SA_TMP/$TABLE_ID.extract.$FILE_ID.fast_export$UOW_APPEND.$FILE_DATETIME.log"})
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter FEXP_LOGFILE of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export CNDTL_EXTRACT_REFORMAT;CNDTL_EXTRACT_REFORMAT=$(grep "^CNDTL_EXTRACT_REFORMAT\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print ${VALUE:-0})
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CNDTL_EXTRACT_REFORMAT of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export CNDTL_EXTRACT_PARTITION;CNDTL_EXTRACT_PARTITION=$(grep "^CNDTL_EXTRACT_PARTITION\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print ${VALUE:-0})
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CNDTL_EXTRACT_PARTITION of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export CNDTL_EXTRACT_PARTITION_LAYOUT;CNDTL_EXTRACT_PARTITION_LAYOUT=$(if [[ $CNDTL_EXTRACT_PARTITION -eq 1 ]]
  then
        grep "^CNDTL_EXTRACT_PARTITION_LAYOUT\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print ${VALUE:-$OUTPUT_FILE}
  else
        print $OUTPUT_FILE
  fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CNDTL_EXTRACT_PARTITION_LAYOUT of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export OUTPUT_DML;OUTPUT_DML=$(if (($CNDTL_EXTRACT_REFORMAT))
then
  print $DW_DML/$ETL_ID.extract_write.dml
else
  print $INPUT_DML
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter OUTPUT_DML of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
export REFORMAT_TRANS_FILE;REFORMAT_TRANS_FILE="$DW_XFR"'/'"$ETL_ID"'.extract_reformat.xfr'
export QUERY_BAND_STRING;QUERY_BAND_STRING=$(
grep "^FEXP_QUERY_BAND\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; 
if [[ "X"$VALUE != "X" ]]
then
print "$VALUE$QUERY_BAND_STRING"
else
print "$QUERY_BAND_STRING"
fi
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter QUERY_BAND_STRING of single_table_extract', interpretation 'shell'
   exit $mpjret
fi
(
   # Parameters of Gather Extract Logs
   LogFile="$EXTRACT_LOG_FILE"
   StartText=Start
   EndText=End
   condition=$( if [[ $EXTRACT_TYPE = "O" ]]; then print "1"; else print "0"; fi)
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of Gather_Extract_Logs', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Gather_Extract_Logs__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
(
   # Parameters of Gather Extract Logs-1
   LogFile="$EXTRACT_LOG_FILE"
   StartText=Start
   EndText=End
   condition=$( if [[ $EXTRACT_TYPE = "T" && $TD_USE_API = 0 ]]; then print "1"; else print "0"; fi)
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of Gather_Extract_Logs_1', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Gather_Extract_Logs_1__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
(
   # Parameters of Gather Extract Logs-2
   LogFile="$EXTRACT_LOG_FILE"
   StartText=Start
   EndText=End
   condition=$( if [[ $EXTRACT_TYPE = "S" ]]; then print "1"; else print "0"; fi)
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of Gather_Extract_Logs_2', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Gather_Extract_Logs_2__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
(
   # Parameters of Deflate
   condition=$CNDTL_EXTRACT_COMPRESS
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of Deflate', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Deflate__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
   conditionInputPort=in
   conditionOutputPort=out
   condition_interpretation='Replace with flow'
   compression=$CNDTL_EXTRACT_COMPRESS_LEVEL
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter compression of Deflate', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Deflate__compression= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${compression}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
(
   # Parameters of Input Table-Oracle
   _AB_FILE_NAME__config_file="$AB_IDB_CONFIG"
   if [ -r "${_AB_FILE_NAME__config_file}" ]; then
      config_file=$(< "${_AB_FILE_NAME__config_file}")
      mpjret=$?
      if [ 0 -ne $mpjret ] ; then
         print -- Error evaluating: 'parameter config_file of Input_Table_Oracle__table_', interpretation 'shell'
         exit $mpjret
      fi
   else
      _AB_DBC_PATH=$(m_db find "${_AB_FILE_NAME__config_file}" 2>/dev/null)
      if [ $? = 0 ]; then
         config_file=$(< "${_AB_DBC_PATH}")
         mpjret=$?
         if [ 0 -ne $mpjret ] ; then
            print -- Error evaluating: 'parameter config_file of Input_Table_Oracle__table_', interpretation 'shell'
            exit $mpjret
         fi
      else
         print -r -- 'Warning: cannot read '"'""${_AB_FILE_NAME__config_file}""'"' to define parameter config_file of Input_Table_Oracle__table_'
      fi
   fi
   table_spec="${INPUT_TABLE_SEL}"
   table_spec_kind=select
   db_is_ole=False
   ora_interface=api
   not_ims=True
   not_ims_or_adabas=True
   not_ims_or_neo=True
   supports_num_error=True
   supports_rows_per_commit=True
   db2eee_or_db2ee=False
   supports_native_options=False
   supports_control_file=False
   old_ablocal_prerequisite=True
   supports_ablocal_expr=True
   supports_gen_ldr_datatypes=False
   ftype_pref_nondelimited=True
   supports_batchsize=False
   api_encrypt_data_helper=False
   supports_encrypt_data=False
   interface_in=api
   interface=api
   field_type_preference=variable
   column_delimiter=""
   max_rows=""
   ablocal_expr="$ABLOCAL"
   remove_delimiters=False
   delimiter_replacement=""
   inf_dummy=a
   dummy1=a
   oracle_max_kb="$ORA_MAX_KB"
   parallel_mode=rowid
   _AB_FILE_NAME__include_partitions=""
   if [ -r "${_AB_FILE_NAME__include_partitions}" ]; then
      include_partitions=$(< "${_AB_FILE_NAME__include_partitions}")
      mpjret=$?
      if [ 0 -ne $mpjret ] ; then
         print -- Error evaluating: 'parameter include_partitions of Input_Table_Oracle__table_', interpretation 'shell'
         exit $mpjret
      fi
   else
      print -r -- 'Warning: cannot read '"'""${_AB_FILE_NAME__include_partitions}""'"' to define parameter include_partitions of Input_Table_Oracle__table_'
   fi
   _ab_ims_path_command='m_db ims_path'
   _ab_ims_path_command_params='config_file positional table_spec keyword'
   use_neoview_bulk_out=False
   neo_util_in=False
   neo_util_out=False
   supports_utility_id=False
   use_mssql_bulk_out=False
   as400_util_out=False
   dbms=oracle
   override_mpname=itable
   limit_keyword=0
   ramp_keyword=0.0
   log_group=""
   keyword_map='limit_keyword limit ramp_keyword ramp'
   _ab_insert_statement_supported=False
   _ab_select_statement_supported=True
   condition=$( if [[ $EXTRACT_TYPE = "O" ]]; then print "1"; else print "0"; fi)
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of Input_Table_Oracle__table_', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Input_Table_Oracle__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
(
   # Parameters of Gather Extract Logs-3
   LogFile="$EXTRACT_LOG_FILE"
   StartText=Start
   EndText=End
   condition=$( if [[ $EXTRACT_TYPE = "M" || $EXTRACT_TYPE = "G" ]]; then print "1"; else print "0"; fi)
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of Gather_Extract_Logs_3', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Gather_Extract_Logs_3__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
(
   # Parameters of Input Table-Generic ODBC
   _AB_FILE_NAME__config_file="$AB_IDB_CONFIG"
   if [ -r "${_AB_FILE_NAME__config_file}" ]; then
      config_file=$(< "${_AB_FILE_NAME__config_file}")
      mpjret=$?
      if [ 0 -ne $mpjret ] ; then
         print -- Error evaluating: 'parameter config_file of Input_Table_Generic_ODBC__table_', interpretation 'shell'
         exit $mpjret
      fi
   else
      _AB_DBC_PATH=$(m_db find "${_AB_FILE_NAME__config_file}" 2>/dev/null)
      if [ $? = 0 ]; then
         config_file=$(< "${_AB_DBC_PATH}")
         mpjret=$?
         if [ 0 -ne $mpjret ] ; then
            print -- Error evaluating: 'parameter config_file of Input_Table_Generic_ODBC__table_', interpretation 'shell'
            exit $mpjret
         fi
      else
         print -r -- 'Warning: cannot read '"'""${_AB_FILE_NAME__config_file}""'"' to define parameter config_file of Input_Table_Generic_ODBC__table_'
      fi
   fi
   table_spec="${INPUT_TABLE_SEL}"
   table_spec_kind=select
   db_is_ole=False
   odbc_interface=api
   not_ims=True
   not_ims_or_adabas=True
   not_ims_or_neo=True
   supports_num_error=False
   supports_rows_per_commit=False
   db2eee_or_db2ee=False
   supports_native_options=False
   supports_control_file=False
   old_ablocal_prerequisite=True
   supports_ablocal_expr=True
   supports_gen_ldr_datatypes=False
   ftype_pref_nondelimited=True
   supports_batchsize=False
   api_encrypt_data_helper=False
   supports_encrypt_data=False
   interface_in=api
   interface=api
   field_type_preference=variable
   column_delimiter=""
   max_rows=""
   ablocal_expr=""
   remove_delimiters=False
   delimiter_replacement=""
   inf_dummy=a
   dummy1=a
   _ab_ims_path_command='m_db ims_path'
   _ab_ims_path_command_params='config_file positional table_spec keyword'
   use_neoview_bulk_out=False
   neo_util_in=False
   neo_util_out=False
   supports_utility_id=False
   use_mssql_bulk_out=False
   as400_util_out=False
   dbms=odbc
   override_mpname=itable
   limit_keyword=0
   ramp_keyword=0.0
   log_group=""
   keyword_map='limit_keyword limit ramp_keyword ramp'
   _ab_insert_statement_supported=False
   _ab_select_statement_supported=True
   condition=$( if [[ $EXTRACT_TYPE = "M"  || $EXTRACT_TYPE = "G" ]]; then print "1"; else print "0"; fi)
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of Input_Table_Generic_ODBC__table_', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Input_Table_Generic_ODBC__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
(
   # Parameters of Input Table-Teradata API
   _AB_FILE_NAME__config_file="$AB_IDB_CONFIG"
   if [ -r "${_AB_FILE_NAME__config_file}" ]; then
      config_file=$(< "${_AB_FILE_NAME__config_file}")
      mpjret=$?
      if [ 0 -ne $mpjret ] ; then
         print -- Error evaluating: 'parameter config_file of Input_Table_Teradata_API__table_', interpretation 'shell'
         exit $mpjret
      fi
   else
      _AB_DBC_PATH=$(m_db find "${_AB_FILE_NAME__config_file}" 2>/dev/null)
      if [ $? = 0 ]; then
         config_file=$(< "${_AB_DBC_PATH}")
         mpjret=$?
         if [ 0 -ne $mpjret ] ; then
            print -- Error evaluating: 'parameter config_file of Input_Table_Teradata_API__table_', interpretation 'shell'
            exit $mpjret
         fi
      else
         print -r -- 'Warning: cannot read '"'""${_AB_FILE_NAME__config_file}""'"' to define parameter config_file of Input_Table_Teradata_API__table_'
      fi
   fi
   table_spec="${INPUT_TABLE_SEL}"
   table_spec_kind=select
   db_is_ole=False
   ter_interface_new=api
   ter_interface=api
   not_ims=True
   not_ims_or_adabas=True
   not_ims_or_neo=True
   supports_num_error=False
   supports_rows_per_commit=False
   db2eee_or_db2ee=False
   supports_native_options=False
   supports_control_file=False
   old_ablocal_prerequisite=True
   supports_ablocal_expr=True
   supports_gen_ldr_datatypes=False
   ftype_pref_nondelimited=True
   supports_batchsize=False
   ter_api_encrypt_data=True
   api_encrypt_data_helper=True
   supports_encrypt_data=True
   interface_in=api
   interface=api
   field_type_preference=variable
   column_delimiter=""
   encrypt_data=False
   max_rows=""
   ablocal_expr=""
   remove_delimiters=False
   delimiter_replacement=""
   non_ansimode=True
   inf_dummy=a
   dummy1=a
   ter_util_in=False
   ter_util=False
   ter_wb_in=False
   ter_wb=False
   ter_show_brief=False
   _ab_ims_path_command='m_db ims_path'
   _ab_ims_path_command_params='config_file positional table_spec keyword'
   use_neoview_bulk_out=False
   neo_util_in=False
   neo_util_out=False
   supports_utility_id=False
   use_mssql_bulk_out=False
   as400_util_out=False
   dbms=teradata
   override_mpname=itable
   limit_keyword=0
   ramp_keyword=0.0
   log_group=""
   keyword_map='limit_keyword limit ramp_keyword ramp'
   _ab_insert_statement_supported=True
   _ab_select_statement_supported=True
   condition=$( if [[ $EXTRACT_TYPE = "T" && $TD_USE_API = 1 ]]; then print "1"; else print "0"; fi)
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of Input_Table_Teradata_API__table_', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Input_Table_Teradata_API__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
(
   # Parameters of Gather Extract Logs-4
   LogFile="$EXTRACT_LOG_FILE"
   StartText=Start
   EndText=End
   condition=$( if [[ $EXTRACT_TYPE = "T" && $TD_USE_API = 1 ]]; then print "1"; else print "0"; fi)
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of Gather_Extract_Logs_4', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Gather_Extract_Logs_4__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
(
   # Parameters of Input Table-Teradata Fast Export
   _AB_FILE_NAME__config_file="$AB_IDB_CONFIG"
   if [ -r "${_AB_FILE_NAME__config_file}" ]; then
      config_file=$(< "${_AB_FILE_NAME__config_file}")
      mpjret=$?
      if [ 0 -ne $mpjret ] ; then
         print -- Error evaluating: 'parameter config_file of Input_Table_Teradata_Fast_Export__table_', interpretation 'shell'
         exit $mpjret
      fi
   else
      _AB_DBC_PATH=$(m_db find "${_AB_FILE_NAME__config_file}" 2>/dev/null)
      if [ $? = 0 ]; then
         config_file=$(< "${_AB_DBC_PATH}")
         mpjret=$?
         if [ 0 -ne $mpjret ] ; then
            print -- Error evaluating: 'parameter config_file of Input_Table_Teradata_Fast_Export__table_', interpretation 'shell'
            exit $mpjret
         fi
      else
         print -r -- 'Warning: cannot read '"'""${_AB_FILE_NAME__config_file}""'"' to define parameter config_file of Input_Table_Teradata_Fast_Export__table_'
      fi
   fi
   table_spec="${INPUT_TABLE_SEL}"
   table_spec_kind=select
   db_is_ole=False
   ter_interface_new=FastExport
   ter_interface=FastExport
   not_ims=True
   not_ims_or_adabas=True
   not_ims_or_neo=True
   supports_num_error=False
   supports_rows_per_commit=False
   db2eee_or_db2ee=False
   supports_native_options=False
   supports_control_file=False
   supports_ablocal_expr=False
   supports_gen_ldr_datatypes=False
   ftype_pref_nondelimited=True
   supports_batchsize=False
   ter_api_encrypt_data=True
   api_encrypt_data_helper=True
   supports_encrypt_data=True
   interface_in=FastExport
   interface=FastExport
   field_type_preference=variable
   column_delimiter=""
   encrypt_data=False
   max_rows=""
   inf_dummy=a
   dummy1=a
   ter_util_in=True
   ter_util=True
   ter_wb_in=False
   ter_wb=False
   ter_show_brief=True
   brief=True
   sleep="$FEXP_SLEEP"
   tenacity="$FEXP_TENACITY"
   sessions="$FEXP_SESSION_MAX_FIRST"' '"$FEXP_SESSION_MIN_SECOND"
   logtab_name="$FEXP_LOGTAB"
   no_spool=False
   logfile="$FEXP_LOGFILE"
   trace_directory=""
   axsmod_tracelevel=None
   _ab_ims_path_command='m_db ims_path'
   _ab_ims_path_command_params='config_file positional table_spec keyword'
   use_neoview_bulk_out=False
   neo_util_in=False
   neo_util_out=False
   supports_utility_id=False
   use_mssql_bulk_out=False
   as400_util_out=False
   dbms=teradata
   override_mpname=db-ter-fast-export
   limit_keyword=0
   ramp_keyword=0.0
   keyword_map='limit_keyword limit ramp_keyword ramp'
   _ab_insert_statement_supported=True
   _ab_select_statement_supported=True
   condition=$( if [[ $EXTRACT_TYPE = "T" && $TD_USE_API = 0 ]]; then print "1"; else print "0"; fi)
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of Input_Table_Teradata_Fast_Export__table_', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Input_Table_Teradata_Fast_Export__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
(
   # Parameters of Input Table-Sqlserver
   _AB_FILE_NAME__config_file="$AB_IDB_CONFIG"
   if [ -r "${_AB_FILE_NAME__config_file}" ]; then
      config_file=$(< "${_AB_FILE_NAME__config_file}")
      mpjret=$?
      if [ 0 -ne $mpjret ] ; then
         print -- Error evaluating: 'parameter config_file of Input_Table_Sqlserver__table_', interpretation 'shell'
         exit $mpjret
      fi
   else
      _AB_DBC_PATH=$(m_db find "${_AB_FILE_NAME__config_file}" 2>/dev/null)
      if [ $? = 0 ]; then
         config_file=$(< "${_AB_DBC_PATH}")
         mpjret=$?
         if [ 0 -ne $mpjret ] ; then
            print -- Error evaluating: 'parameter config_file of Input_Table_Sqlserver__table_', interpretation 'shell'
            exit $mpjret
         fi
      else
         print -r -- 'Warning: cannot read '"'""${_AB_FILE_NAME__config_file}""'"' to define parameter config_file of Input_Table_Sqlserver__table_'
      fi
   fi
   table_spec="${INPUT_TABLE_SEL}"
   table_spec_kind=select
   db_is_ole=True
   mssql_interface=api
   ole_interface=api
   not_ims=True
   not_ims_or_adabas=True
   not_ims_or_neo=True
   supports_num_error=True
   supports_rows_per_commit=True
   db2eee_or_db2ee=False
   supports_native_options=False
   supports_control_file=False
   old_ablocal_prerequisite=True
   supports_ablocal_expr=True
   supports_gen_ldr_datatypes=False
   ftype_pref_nondelimited=True
   supports_batchsize=False
   api_encrypt_data_helper=False
   supports_encrypt_data=False
   interface_in=api
   interface=api
   field_type_preference=variable
   column_delimiter=""
   max_rows=""
   ablocal_expr=""
   remove_delimiters=False
   delimiter_replacement=""
   inf_dummy=a
   dummy1=a
   _ab_ims_path_command='m_db ims_path'
   _ab_ims_path_command_params='config_file positional table_spec keyword'
   use_neoview_bulk_out=False
   neo_util_in=False
   neo_util_out=False
   supports_utility_id=False
   use_mssql_bulk_out=False
   as400_util_out=False
   dbms=mssql
   override_mpname=itable
   limit_keyword=0
   ramp_keyword=0.0
   log_group=""
   keyword_map='limit_keyword limit ramp_keyword ramp'
   _ab_insert_statement_supported=False
   _ab_select_statement_supported=True
   condition=$( if [[ $EXTRACT_TYPE = "S" ]]; then print "1"; else print "0"; fi)
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of Input_Table_Sqlserver__table_', interpretation 'shell'
      exit $mpjret
   fi
   print -rn Input_Table_Sqlserver__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
(
   # Parameters of move FEXP_LOGFILE
   commandline=$DW_MASTER_BIN/dw_infra.move_fexp_logfile.ksh
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter commandline of move_FEXP_LOGFILE', interpretation 'shell'
      exit $mpjret
   fi
   print -rn move_FEXP_LOGFILE__commandline= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${commandline}" >> ${_AB_PROXY_DIR}/GDE-Parameters
   condition=$( if [[ $EXTRACT_TYPE = "T" && $TD_USE_API = 0 ]]; then print "1"; else print "0"; fi)
   mpjret=$?
   if [ 0 -ne $mpjret ] ; then
      print -- Error evaluating: 'parameter condition of move_FEXP_LOGFILE', interpretation 'shell'
      exit $mpjret
   fi
   print -rn move_FEXP_LOGFILE__condition= >>${_AB_PROXY_DIR}/GDE-Parameters
   __AB_QUOTEIT "${condition}" >> ${_AB_PROXY_DIR}/GDE-Parameters
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then exit $mpjret ; fi
. ./${_AB_PROXY_DIR}/GDE-Parameters

#+Script Start+  ==================== Edits in this section are preserved.
m_env -v


if [ -z $LAST_EXTRACT_TYPE ]
then
   print "$0: Error: LAST_EXTRACT_TYPE variable not set"
   exit 4
fi

if [[ $LAST_EXTRACT_TYPE != "N" && -z $FROM_EXTRACT_VALUE ]]
then
   print "$0: Error: FROM_EXTRACT_VALUE variable not set"
   exit 4
fi

if [[ $LAST_EXTRACT_TYPE = "V" && -z $TO_EXTRACT_VALUE ]]
then
   print "$0: Error: TO_EXTRACT_VALUE variable not set"
   exit 4
fi

if [ -z $ORA_MAX_KB ]
then
   print "$0: Error: ORA_MAX_KB variable not set"
   exit 4
fi

if [[ $LAST_EXTRACT_TYPE = "R" && -z $ROLLUP_FIELD ]]
then
   print "$0: Error: ROLLUP_FIELD variable not set"
   exit 4
fi

if [ -z $BATCH_SEQ_NUM ]
then
   print "$0: Error: BATCH_SEQ_NUM variable not set"
   exit 4
fi

if [ -z $ORA_USERNAME ]
then
   print "$0: Error: ORA_USERNAME variable not set.  May be due to missing TNS_NAME or invalid record format in $DW_LOGINS/ora_logins.dat"
   exit 4
fi

if [ -z $ORA_PASSWORD ]
then
   print "$0: Error: ORA_PASSWORD variable not set.  May be due to missing TNS_NAME or invalid record format in $DW_LOGINS/ora_logins.dat"
   exit 4
fi

#+End Script Start+  ====================
# Check that the "mp" program is found correctly on the PATH
case "$_ab_uname" in
  Windows_* )
    _ab_expected_mp=$AB_HOME/bin/mp.exe ;;
  * )
    _ab_expected_mp=$AB_HOME/bin/mp
esac
if [ ! -x "$_ab_expected_mp" ]; then
  print "\n*** ERROR: executable $_ab_expected_mp not found"
  exit 1
fi
_ab_found_mp=$(whence mp)
if [ "$_ab_found_mp" = "" ] || [ "$_ab_found_mp" -ot "$_ab_expected_mp" ] || [ "$_ab_found_mp" -nt "$_ab_expected_mp" ]; then
  if [ "$_ab_found_mp" = "" ]; then
    print "\n*** ERROR: mp not found on PATH"
  else
    case "$_ab_uname" in
      CYGWIN_* )
        _ab_found_mp=`cygpath -m "$_ab_found_mp"` ;;
    esac
    print "\n*** ERROR: Wrong mp found on the PATH: $_ab_found_mp"
    print "           Should be via \$AB_HOME/bin: $_ab_expected_mp"
  fi
  print "\nCheck Setup Script in Host Connections Settings and Script Start in Graph Settings for PATH modifications"
  print "Active PATH=$PATH"
  exit 1
fi
if [ -f "$AB_HOME/bin/ab_catalog_functions.ksh" ]; then . ab_catalog_functions.ksh; fi
mv "${_AB_PROXY_DIR}" "${AB_JOB}"'-single_table_extract-ProxyDir'
_AB_PROXY_DIR="${AB_JOB}"'-single_table_extract-ProxyDir'
print -r -- 'record string("|") node, timestamp, component, subcomponent, event_type; string("|\n") event_text; end' > "${_AB_PROXY_DIR}"'/Input_Table_Generic_ODBC-3.dml'
print -r -- 'void(1)' > "${_AB_PROXY_DIR}"'/Deflate-6.dml'
print -r -- 'out::rollup(in) =
begin
  out.last_extract_value :: (string("\n")) first_defined(max(in.'"${ROLLUP_FIELD}"'), NULL);                  
end;' > "${_AB_PROXY_DIR}"'/Get_Max_Value_for_Extract_Field-7.xfr'
print -r -- 'record
  string("\n") last_extract_value;
end;' > "${_AB_PROXY_DIR}"'/Last_Extract_Value_File_1-8.dml'
print -r -- 'record
  string("\n") line;
end;' > "${_AB_PROXY_DIR}"'/Extract_Log_File-9.dml'
print -r -- 'out::reformat(in) =
begin
  let integer(4) teradata_start =string_index(in.line, "UTY8722") + 8;
  let integer(4) oracle_start =string_index(in.line, "unload|rows|Rows unloaded:") + 27;
  let integer(4) start_rec_count =teradata_start > oracle_start ? teradata_start : oracle_start;
  let integer(4) end_rec_count =teradata_start > oracle_start ? string_length(in.line) - 38 : string_length(in.line);

  out.record_count :1: string_substring(in.line,start_rec_count,end_rec_count-start_rec_count);
end;' > "${_AB_PROXY_DIR}"'/Reformat-10.xfr'
print -r -- 'record
  decimal("\n") record_count;
end;' > "${_AB_PROXY_DIR}"'/Reformat-11.dml'
print -r -- 'out::rollup(in) =
begin
  out.record_count :: sum(in.record_count);
end;' > "${_AB_PROXY_DIR}"'/Rollup_Record_Counts-12.xfr'
print -r -- 'record
  decimal("\n", 0) record_count;
end;' > "${_AB_PROXY_DIR}"'/Rollup_Record_Counts-13.dml'
print -r -- 'record
  string(1) a;
end;' > "${_AB_PROXY_DIR}"'/Send_Primer_Row_to_Reformat-14.dml'
print -r -- 'out::reformat(in) =
begin
  out.last_extract_value :: $TO_EXTRACT_VALUE;
end;' > "${_AB_PROXY_DIR}"'/Update_Last_Extract_Value_File-15.xfr'

mp job ${AB_JOB}

# Layouts:
mp layout layout1 "$CNDTL_EXTRACT_PARTITION_LAYOUT"
mp layout layout2 file:.
mp layout layout3 "$DW_TMP"
mp layout layout4 'file:'"$LAST_EXTRACT_VALUE_FILE"

# Record Formats (Metadata):
mp metadata metadata1 -file "$INPUT_DML"
mp metadata metadata2 -file "${_AB_PROXY_DIR}"'/Input_Table_Generic_ODBC-3.dml'
mp metadata metadata3 -file "$OUTPUT_DML"
mp metadata metadata4 -file "${_AB_PROXY_DIR}"'/Deflate-6.dml'
mp metadata metadata5 -file "${_AB_PROXY_DIR}"'/Last_Extract_Value_File_1-8.dml'
mp metadata metadata6 -file "${_AB_PROXY_DIR}"'/Extract_Log_File-9.dml'
mp metadata metadata7 -file "${_AB_PROXY_DIR}"'/Reformat-11.dml'
mp metadata metadata8 -file "${_AB_PROXY_DIR}"'/Rollup_Record_Counts-13.dml'
mp metadata metadata9 -file "${_AB_PROXY_DIR}"'/Send_Primer_Row_to_Reformat-14.dml'

export AB_CATALOG;AB_CATALOG=${AB_CATALOG:-"${XX_CATALOG}"}
# Catalog Usage: Creating temporary catalog using lookup files only
m_rmcatalog -catalog GDE-single_table_extract-${AB_JOB}.cat > /dev/null 2>&1
m_mkcatalog -catalog GDE-single_table_extract-${AB_JOB}.cat
SAVED_CATALOG="${AB_CATALOG}"
export AB_CATALOG;AB_CATALOG='GDE-single_table_extract-'"${AB_JOB}"'.cat'
# 
# Initialize condition variables to user-specified conditions
# 
AB_USERCOND_single_table_extract=1
AB_IS_LIVE_single_table_extract=1
AB_USERCOND_Extract_Log_File=1
AB_IS_LIVE_Extract_Log_File=1
AB_HAS_DATA_Flow_7=1
AB_USERCOND_Reformat=1
AB_IS_LIVE_Reformat=1
AB_HAS_DATA_Flow_9=1
AB_USERCOND_Rollup_Record_Counts=1
AB_IS_LIVE_Rollup_Record_Counts=1
AB_HAS_DATA_Flow_10=1
AB_USERCOND_Record_Count_File=1
AB_IS_LIVE_Record_Count_File=1
AB_USERCOND_Input_Table_Generic_ODBC__table_="$Input_Table_Generic_ODBC__condition"
AB_USERCOND_Input_Table_Generic_ODBC__table_=$(__AB_COND "${AB_USERCOND_Input_Table_Generic_ODBC__table_}")
AB_IS_LIVE_Input_Table_Generic_ODBC__table_=1
AB_HAS_DATA_Flow_18=1
AB_HAS_DATA_Flow_17=1
AB_USERCOND_Gather_Extract_Logs_3="$Gather_Extract_Logs_3__condition"
AB_USERCOND_Gather_Extract_Logs_3=$(__AB_COND "${AB_USERCOND_Gather_Extract_Logs_3}")
AB_IS_LIVE_Gather_Extract_Logs_3=1
AB_USERCOND_Input_Table_Oracle__table_="$Input_Table_Oracle__condition"
AB_USERCOND_Input_Table_Oracle__table_=$(__AB_COND "${AB_USERCOND_Input_Table_Oracle__table_}")
AB_IS_LIVE_Input_Table_Oracle__table_=1
AB_HAS_DATA_Flow_2=1
AB_HAS_DATA_Flow_1=1
AB_USERCOND_Gather_Extract_Logs="$Gather_Extract_Logs__condition"
AB_USERCOND_Gather_Extract_Logs=$(__AB_COND "${AB_USERCOND_Gather_Extract_Logs}")
AB_IS_LIVE_Gather_Extract_Logs=1
AB_USERCOND_Input_Table_Sqlserver__table_="$Input_Table_Sqlserver__condition"
AB_USERCOND_Input_Table_Sqlserver__table_=$(__AB_COND "${AB_USERCOND_Input_Table_Sqlserver__table_}")
AB_IS_LIVE_Input_Table_Sqlserver__table_=1
AB_HAS_DATA_Flow_8=1
AB_HAS_DATA_Flow_15=1
AB_USERCOND_Gather_Extract_Logs_2="$Gather_Extract_Logs_2__condition"
AB_USERCOND_Gather_Extract_Logs_2=$(__AB_COND "${AB_USERCOND_Gather_Extract_Logs_2}")
AB_IS_LIVE_Gather_Extract_Logs_2=1
AB_USERCOND_Input_Table_Teradata_API__table_="$Input_Table_Teradata_API__condition"
AB_USERCOND_Input_Table_Teradata_API__table_=$(__AB_COND "${AB_USERCOND_Input_Table_Teradata_API__table_}")
AB_IS_LIVE_Input_Table_Teradata_API__table_=1
AB_HAS_DATA_Flow_20=1
AB_HAS_DATA_Flow_19=1
AB_USERCOND_Gather_Extract_Logs_4="$Gather_Extract_Logs_4__condition"
AB_USERCOND_Gather_Extract_Logs_4=$(__AB_COND "${AB_USERCOND_Gather_Extract_Logs_4}")
AB_IS_LIVE_Gather_Extract_Logs_4=1
AB_USERCOND_Input_Table_Teradata_Fast_Export__table_="$Input_Table_Teradata_Fast_Export__condition"
AB_USERCOND_Input_Table_Teradata_Fast_Export__table_=$(__AB_COND "${AB_USERCOND_Input_Table_Teradata_Fast_Export__table_}")
AB_IS_LIVE_Input_Table_Teradata_Fast_Export__table_=1
AB_HAS_DATA_Flow_14=1
AB_HAS_DATA_Flow_13=1
AB_USERCOND_Gather_Extract_Logs_1="$Gather_Extract_Logs_1__condition"
AB_USERCOND_Gather_Extract_Logs_1=$(__AB_COND "${AB_USERCOND_Gather_Extract_Logs_1}")
AB_IS_LIVE_Gather_Extract_Logs_1=1
AB_USERCOND_Replicate="$CNDTL_LAST_EXTRACT_ROLLUP"
AB_USERCOND_Replicate=$(__AB_COND "${AB_USERCOND_Replicate}")
AB_IS_LIVE_Replicate=1
AB_HAS_DATA_Flow_16=1
AB_HAS_DATA_Flow_5=1
AB_USERCOND_Conditional_Partition_by_Round_robin="$CNDTL_EXTRACT_PARTITION"
AB_USERCOND_Conditional_Partition_by_Round_robin=$(__AB_COND "${AB_USERCOND_Conditional_Partition_by_Round_robin}")
AB_IS_LIVE_Conditional_Partition_by_Round_robin=1
AB_HAS_DATA_Flow_11=1
AB_USERCOND_Retain_Flow_to_Flow="$CNDTL_EXTRACT_PARTITION"
AB_USERCOND_Retain_Flow_to_Flow=$(__AB_COND "${AB_USERCOND_Retain_Flow_to_Flow}")
AB_IS_LIVE_Retain_Flow_to_Flow=1
AB_HAS_DATA_Flow_23=1
AB_USERCOND_Conditional_Extract_Reformat="$CNDTL_EXTRACT_REFORMAT"
AB_USERCOND_Conditional_Extract_Reformat=$(__AB_COND "${AB_USERCOND_Conditional_Extract_Reformat}")
AB_IS_LIVE_Conditional_Extract_Reformat=1
AB_HAS_DATA_Flow_21=1
AB_USERCOND_Deflate="$Deflate__condition"
AB_USERCOND_Deflate=$(__AB_COND "${AB_USERCOND_Deflate}")
AB_IS_LIVE_Deflate=1
AB_HAS_DATA_Flow_22=1
AB_USERCOND_Output_File=1
AB_IS_LIVE_Output_File=1
AB_USERCOND_Send_From_Extract_Value_to_Rollup="$CNDTL_LAST_EXTRACT_ROLLUP"
AB_USERCOND_Send_From_Extract_Value_to_Rollup=$(__AB_COND "${AB_USERCOND_Send_From_Extract_Value_to_Rollup}")
AB_IS_LIVE_Send_From_Extract_Value_to_Rollup=1
AB_HAS_DATA_Flow_3=1
AB_USERCOND_Get_Max_Value_for_Extract_Field="$CNDTL_LAST_EXTRACT_ROLLUP"
AB_USERCOND_Get_Max_Value_for_Extract_Field=$(__AB_COND "${AB_USERCOND_Get_Max_Value_for_Extract_Field}")
AB_IS_LIVE_Get_Max_Value_for_Extract_Field=1
AB_HAS_DATA_Flow_6=1
AB_USERCOND_Last_Extract_Value_File_1="$CNDTL_LAST_EXTRACT_ROLLUP"
AB_USERCOND_Last_Extract_Value_File_1=$(__AB_COND "${AB_USERCOND_Last_Extract_Value_File_1}")
AB_IS_LIVE_Last_Extract_Value_File_1=1
AB_USERCOND_Send_Primer_Row_to_Reformat="$CNDTL_LAST_EXTRACT_VARIABLE"
AB_USERCOND_Send_Primer_Row_to_Reformat=$(__AB_COND "${AB_USERCOND_Send_Primer_Row_to_Reformat}")
AB_IS_LIVE_Send_Primer_Row_to_Reformat=1
AB_HAS_DATA_Flow_4=1
AB_USERCOND_Update_Last_Extract_Value_File="$CNDTL_LAST_EXTRACT_VARIABLE"
AB_USERCOND_Update_Last_Extract_Value_File=$(__AB_COND "${AB_USERCOND_Update_Last_Extract_Value_File}")
AB_IS_LIVE_Update_Last_Extract_Value_File=1
AB_HAS_DATA_Flow_12=1
AB_USERCOND_Last_Extract_Value_File="$CNDTL_LAST_EXTRACT_VARIABLE"
AB_USERCOND_Last_Extract_Value_File=$(__AB_COND "${AB_USERCOND_Last_Extract_Value_File}")
AB_IS_LIVE_Last_Extract_Value_File=1
AB_USERCOND_move_FEXP_LOGFILE="$move_FEXP_LOGFILE__condition"
AB_USERCOND_move_FEXP_LOGFILE=$(__AB_COND "${AB_USERCOND_move_FEXP_LOGFILE}")
AB_IS_LIVE_move_FEXP_LOGFILE=1
# 
# Compute condition variables by considering the conditions of neighboring components
# 
done=false
while [ $done = false ] ; do
   done=true
   Temp="${AB_IS_LIVE_Input_Table_Generic_ODBC__table_}"
   let AB_IS_LIVE_Input_Table_Generic_ODBC__table_="(AB_HAS_DATA_Flow_18) && (AB_USERCOND_Input_Table_Generic_ODBC__table_)"
   if [ X"${AB_IS_LIVE_Input_Table_Generic_ODBC__table_}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_18}"
   let AB_HAS_DATA_Flow_18="(AB_IS_LIVE_Input_Table_Generic_ODBC__table_) && ((AB_IS_LIVE_Replicate) || ((AB_HAS_DATA_Flow_16) || (AB_HAS_DATA_Flow_5)))"
   if [ X"${AB_HAS_DATA_Flow_18}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_17}"
   let AB_HAS_DATA_Flow_17="(AB_IS_LIVE_Input_Table_Generic_ODBC__table_) && (AB_IS_LIVE_Gather_Extract_Logs_3)"
   if [ X"${AB_HAS_DATA_Flow_17}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Gather_Extract_Logs_3}"
   let AB_IS_LIVE_Gather_Extract_Logs_3="(AB_HAS_DATA_Flow_17) && (AB_USERCOND_Gather_Extract_Logs_3)"
   if [ X"${AB_IS_LIVE_Gather_Extract_Logs_3}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Input_Table_Oracle__table_}"
   let AB_IS_LIVE_Input_Table_Oracle__table_="(AB_HAS_DATA_Flow_2) && (AB_USERCOND_Input_Table_Oracle__table_)"
   if [ X"${AB_IS_LIVE_Input_Table_Oracle__table_}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_2}"
   let AB_HAS_DATA_Flow_2="(AB_IS_LIVE_Input_Table_Oracle__table_) && ((AB_IS_LIVE_Replicate) || ((AB_HAS_DATA_Flow_16) || (AB_HAS_DATA_Flow_5)))"
   if [ X"${AB_HAS_DATA_Flow_2}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_1}"
   let AB_HAS_DATA_Flow_1="(AB_IS_LIVE_Input_Table_Oracle__table_) && (AB_IS_LIVE_Gather_Extract_Logs)"
   if [ X"${AB_HAS_DATA_Flow_1}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Gather_Extract_Logs}"
   let AB_IS_LIVE_Gather_Extract_Logs="(AB_HAS_DATA_Flow_1) && (AB_USERCOND_Gather_Extract_Logs)"
   if [ X"${AB_IS_LIVE_Gather_Extract_Logs}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Input_Table_Sqlserver__table_}"
   let AB_IS_LIVE_Input_Table_Sqlserver__table_="(AB_HAS_DATA_Flow_8) && (AB_USERCOND_Input_Table_Sqlserver__table_)"
   if [ X"${AB_IS_LIVE_Input_Table_Sqlserver__table_}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_8}"
   let AB_HAS_DATA_Flow_8="(AB_IS_LIVE_Input_Table_Sqlserver__table_) && ((AB_IS_LIVE_Replicate) || ((AB_HAS_DATA_Flow_16) || (AB_HAS_DATA_Flow_5)))"
   if [ X"${AB_HAS_DATA_Flow_8}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_15}"
   let AB_HAS_DATA_Flow_15="(AB_IS_LIVE_Input_Table_Sqlserver__table_) && (AB_IS_LIVE_Gather_Extract_Logs_2)"
   if [ X"${AB_HAS_DATA_Flow_15}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Gather_Extract_Logs_2}"
   let AB_IS_LIVE_Gather_Extract_Logs_2="(AB_HAS_DATA_Flow_15) && (AB_USERCOND_Gather_Extract_Logs_2)"
   if [ X"${AB_IS_LIVE_Gather_Extract_Logs_2}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Input_Table_Teradata_API__table_}"
   let AB_IS_LIVE_Input_Table_Teradata_API__table_="(AB_HAS_DATA_Flow_20) && (AB_USERCOND_Input_Table_Teradata_API__table_)"
   if [ X"${AB_IS_LIVE_Input_Table_Teradata_API__table_}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_20}"
   let AB_HAS_DATA_Flow_20="(AB_IS_LIVE_Input_Table_Teradata_API__table_) && ((AB_IS_LIVE_Replicate) || ((AB_HAS_DATA_Flow_16) || (AB_HAS_DATA_Flow_5)))"
   if [ X"${AB_HAS_DATA_Flow_20}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_19}"
   let AB_HAS_DATA_Flow_19="(AB_IS_LIVE_Input_Table_Teradata_API__table_) && (AB_IS_LIVE_Gather_Extract_Logs_4)"
   if [ X"${AB_HAS_DATA_Flow_19}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Gather_Extract_Logs_4}"
   let AB_IS_LIVE_Gather_Extract_Logs_4="(AB_HAS_DATA_Flow_19) && (AB_USERCOND_Gather_Extract_Logs_4)"
   if [ X"${AB_IS_LIVE_Gather_Extract_Logs_4}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Input_Table_Teradata_Fast_Export__table_}"
   let AB_IS_LIVE_Input_Table_Teradata_Fast_Export__table_="(AB_HAS_DATA_Flow_14) && (AB_USERCOND_Input_Table_Teradata_Fast_Export__table_)"
   if [ X"${AB_IS_LIVE_Input_Table_Teradata_Fast_Export__table_}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_14}"
   let AB_HAS_DATA_Flow_14="(AB_IS_LIVE_Input_Table_Teradata_Fast_Export__table_) && ((AB_IS_LIVE_Replicate) || ((AB_HAS_DATA_Flow_16) || (AB_HAS_DATA_Flow_5)))"
   if [ X"${AB_HAS_DATA_Flow_14}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_13}"
   let AB_HAS_DATA_Flow_13="(AB_IS_LIVE_Input_Table_Teradata_Fast_Export__table_) && (AB_IS_LIVE_Gather_Extract_Logs_1)"
   if [ X"${AB_HAS_DATA_Flow_13}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Gather_Extract_Logs_1}"
   let AB_IS_LIVE_Gather_Extract_Logs_1="(AB_HAS_DATA_Flow_13) && (AB_USERCOND_Gather_Extract_Logs_1)"
   if [ X"${AB_IS_LIVE_Gather_Extract_Logs_1}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Replicate}"
   let AB_IS_LIVE_Replicate="(((((AB_HAS_DATA_Flow_14) || (AB_HAS_DATA_Flow_20)) || (AB_HAS_DATA_Flow_2)) || (AB_HAS_DATA_Flow_8)) || (AB_HAS_DATA_Flow_18)) && ((AB_USERCOND_Replicate) || ((((AB_HAS_DATA_Flow_14+AB_HAS_DATA_Flow_20+AB_HAS_DATA_Flow_2+AB_HAS_DATA_Flow_8+AB_HAS_DATA_Flow_18) > 1)) || (((AB_HAS_DATA_Flow_16+AB_HAS_DATA_Flow_5) > 1))))"
   if [ X"${AB_IS_LIVE_Replicate}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_16}"
   let AB_HAS_DATA_Flow_16="((AB_IS_LIVE_Replicate) || (((((AB_HAS_DATA_Flow_14) || (AB_HAS_DATA_Flow_20)) || (AB_HAS_DATA_Flow_2)) || (AB_HAS_DATA_Flow_8)) || (AB_HAS_DATA_Flow_18))) && ((AB_IS_LIVE_Conditional_Partition_by_Round_robin) || (AB_HAS_DATA_Flow_11))"
   if [ X"${AB_HAS_DATA_Flow_16}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_5}"
   let AB_HAS_DATA_Flow_5="((AB_IS_LIVE_Replicate) || (((((AB_HAS_DATA_Flow_14) || (AB_HAS_DATA_Flow_20)) || (AB_HAS_DATA_Flow_2)) || (AB_HAS_DATA_Flow_8)) || (AB_HAS_DATA_Flow_18))) && (AB_IS_LIVE_Get_Max_Value_for_Extract_Field)"
   if [ X"${AB_HAS_DATA_Flow_5}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Conditional_Partition_by_Round_robin}"
   let AB_IS_LIVE_Conditional_Partition_by_Round_robin="((AB_HAS_DATA_Flow_16) && (AB_HAS_DATA_Flow_11)) && ((AB_USERCOND_Conditional_Partition_by_Round_robin) || ((((AB_HAS_DATA_Flow_16) > 1)) || (((AB_HAS_DATA_Flow_11) > 1))))"
   if [ X"${AB_IS_LIVE_Conditional_Partition_by_Round_robin}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_11}"
   let AB_HAS_DATA_Flow_11="((AB_IS_LIVE_Conditional_Partition_by_Round_robin) || (AB_HAS_DATA_Flow_16)) && ((AB_IS_LIVE_Retain_Flow_to_Flow) || (AB_HAS_DATA_Flow_23))"
   if [ X"${AB_HAS_DATA_Flow_11}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Retain_Flow_to_Flow}"
   let AB_IS_LIVE_Retain_Flow_to_Flow="(AB_HAS_DATA_Flow_11) && ((AB_USERCOND_Retain_Flow_to_Flow) || ((((AB_HAS_DATA_Flow_11) > 1)) || (((AB_HAS_DATA_Flow_23) > 1))))"
   if [ X"${AB_IS_LIVE_Retain_Flow_to_Flow}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_23}"
   let AB_HAS_DATA_Flow_23="((AB_IS_LIVE_Retain_Flow_to_Flow) || (AB_HAS_DATA_Flow_11)) && ((AB_IS_LIVE_Conditional_Extract_Reformat) || (AB_HAS_DATA_Flow_21))"
   if [ X"${AB_HAS_DATA_Flow_23}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Conditional_Extract_Reformat}"
   let AB_IS_LIVE_Conditional_Extract_Reformat="((AB_HAS_DATA_Flow_23) && (((AB_HAS_DATA_Flow_21) != 0))) && ((AB_USERCOND_Conditional_Extract_Reformat) || ((((AB_HAS_DATA_Flow_23) > 1)) || (((AB_HAS_DATA_Flow_21) > 1))))"
   if [ X"${AB_IS_LIVE_Conditional_Extract_Reformat}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_21}"
   let AB_HAS_DATA_Flow_21="((AB_IS_LIVE_Conditional_Extract_Reformat) || (AB_HAS_DATA_Flow_23)) && ((AB_IS_LIVE_Deflate) || (AB_HAS_DATA_Flow_22))"
   if [ X"${AB_HAS_DATA_Flow_21}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Deflate}"
   let AB_IS_LIVE_Deflate="((AB_HAS_DATA_Flow_21) && (AB_HAS_DATA_Flow_22)) && ((AB_USERCOND_Deflate) || ((((AB_HAS_DATA_Flow_21) > 1)) || (((AB_HAS_DATA_Flow_22) > 1))))"
   if [ X"${AB_IS_LIVE_Deflate}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_22}"
   let AB_HAS_DATA_Flow_22="(AB_IS_LIVE_Deflate) || (AB_HAS_DATA_Flow_21)"
   if [ X"${AB_HAS_DATA_Flow_22}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Send_From_Extract_Value_to_Rollup}"
   let AB_IS_LIVE_Send_From_Extract_Value_to_Rollup="(AB_HAS_DATA_Flow_3) && (AB_USERCOND_Send_From_Extract_Value_to_Rollup)"
   if [ X"${AB_IS_LIVE_Send_From_Extract_Value_to_Rollup}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_3}"
   let AB_HAS_DATA_Flow_3="(AB_IS_LIVE_Send_From_Extract_Value_to_Rollup) && (AB_IS_LIVE_Get_Max_Value_for_Extract_Field)"
   if [ X"${AB_HAS_DATA_Flow_3}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Get_Max_Value_for_Extract_Field}"
   let AB_IS_LIVE_Get_Max_Value_for_Extract_Field="(((AB_HAS_DATA_Flow_5) || (AB_HAS_DATA_Flow_3)) && (AB_HAS_DATA_Flow_6)) && (AB_USERCOND_Get_Max_Value_for_Extract_Field)"
   if [ X"${AB_IS_LIVE_Get_Max_Value_for_Extract_Field}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_6}"
   let AB_HAS_DATA_Flow_6="(AB_IS_LIVE_Get_Max_Value_for_Extract_Field) && (AB_IS_LIVE_Last_Extract_Value_File_1)"
   if [ X"${AB_HAS_DATA_Flow_6}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Last_Extract_Value_File_1}"
   let AB_IS_LIVE_Last_Extract_Value_File_1="AB_USERCOND_Last_Extract_Value_File_1"
   if [ X"${AB_IS_LIVE_Last_Extract_Value_File_1}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Send_Primer_Row_to_Reformat}"
   let AB_IS_LIVE_Send_Primer_Row_to_Reformat="(AB_HAS_DATA_Flow_4) && (AB_USERCOND_Send_Primer_Row_to_Reformat)"
   if [ X"${AB_IS_LIVE_Send_Primer_Row_to_Reformat}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_4}"
   let AB_HAS_DATA_Flow_4="(AB_IS_LIVE_Send_Primer_Row_to_Reformat) && (AB_IS_LIVE_Update_Last_Extract_Value_File)"
   if [ X"${AB_HAS_DATA_Flow_4}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Update_Last_Extract_Value_File}"
   let AB_IS_LIVE_Update_Last_Extract_Value_File="((AB_HAS_DATA_Flow_4) && (((AB_HAS_DATA_Flow_12) != 0))) && (AB_USERCOND_Update_Last_Extract_Value_File)"
   if [ X"${AB_IS_LIVE_Update_Last_Extract_Value_File}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_12}"
   let AB_HAS_DATA_Flow_12="(AB_IS_LIVE_Update_Last_Extract_Value_File) && (AB_IS_LIVE_Last_Extract_Value_File)"
   if [ X"${AB_HAS_DATA_Flow_12}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_Last_Extract_Value_File}"
   let AB_IS_LIVE_Last_Extract_Value_File="AB_USERCOND_Last_Extract_Value_File"
   if [ X"${AB_IS_LIVE_Last_Extract_Value_File}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_move_FEXP_LOGFILE}"
   let AB_IS_LIVE_move_FEXP_LOGFILE="AB_USERCOND_move_FEXP_LOGFILE"
   if [ X"${AB_IS_LIVE_move_FEXP_LOGFILE}" != X"$Temp" ]; then
      done=false
   fi
done
# 
if [ X"${AB_VERBOSE_CONDITIONS}" != X"" ]; then
   # 
   # echo condition variables
   # 
   print -r -- 'AB_USERCOND_single_table_extract=1'
   print -r -- 'AB_IS_LIVE_single_table_extract=1'
   print -r -- 'AB_USERCOND_Extract_Log_File=1'
   print -r -- 'AB_IS_LIVE_Extract_Log_File=1'
   print -r -- 'AB_HAS_DATA_Flow_7=1'
   print -r -- 'AB_USERCOND_Reformat=1'
   print -r -- 'AB_IS_LIVE_Reformat=1'
   print -r -- 'AB_HAS_DATA_Flow_9=1'
   print -r -- 'AB_USERCOND_Rollup_Record_Counts=1'
   print -r -- 'AB_IS_LIVE_Rollup_Record_Counts=1'
   print -r -- 'AB_HAS_DATA_Flow_10=1'
   print -r -- 'AB_USERCOND_Record_Count_File=1'
   print -r -- 'AB_IS_LIVE_Record_Count_File=1'
   print -r -- 'AB_USERCOND_Input_Table_Generic_ODBC__table_='"${AB_USERCOND_Input_Table_Generic_ODBC__table_}"
   print -r -- 'AB_IS_LIVE_Input_Table_Generic_ODBC__table_='"${AB_IS_LIVE_Input_Table_Generic_ODBC__table_}"
   print -r -- 'AB_HAS_DATA_Flow_18='"${AB_HAS_DATA_Flow_18}"
   print -r -- 'AB_HAS_DATA_Flow_17='"${AB_HAS_DATA_Flow_17}"
   print -r -- 'AB_USERCOND_Gather_Extract_Logs_3='"${AB_USERCOND_Gather_Extract_Logs_3}"
   print -r -- 'AB_IS_LIVE_Gather_Extract_Logs_3='"${AB_IS_LIVE_Gather_Extract_Logs_3}"
   print -r -- 'AB_USERCOND_Input_Table_Oracle__table_='"${AB_USERCOND_Input_Table_Oracle__table_}"
   print -r -- 'AB_IS_LIVE_Input_Table_Oracle__table_='"${AB_IS_LIVE_Input_Table_Oracle__table_}"
   print -r -- 'AB_HAS_DATA_Flow_2='"${AB_HAS_DATA_Flow_2}"
   print -r -- 'AB_HAS_DATA_Flow_1='"${AB_HAS_DATA_Flow_1}"
   print -r -- 'AB_USERCOND_Gather_Extract_Logs='"${AB_USERCOND_Gather_Extract_Logs}"
   print -r -- 'AB_IS_LIVE_Gather_Extract_Logs='"${AB_IS_LIVE_Gather_Extract_Logs}"
   print -r -- 'AB_USERCOND_Input_Table_Sqlserver__table_='"${AB_USERCOND_Input_Table_Sqlserver__table_}"
   print -r -- 'AB_IS_LIVE_Input_Table_Sqlserver__table_='"${AB_IS_LIVE_Input_Table_Sqlserver__table_}"
   print -r -- 'AB_HAS_DATA_Flow_8='"${AB_HAS_DATA_Flow_8}"
   print -r -- 'AB_HAS_DATA_Flow_15='"${AB_HAS_DATA_Flow_15}"
   print -r -- 'AB_USERCOND_Gather_Extract_Logs_2='"${AB_USERCOND_Gather_Extract_Logs_2}"
   print -r -- 'AB_IS_LIVE_Gather_Extract_Logs_2='"${AB_IS_LIVE_Gather_Extract_Logs_2}"
   print -r -- 'AB_USERCOND_Input_Table_Teradata_API__table_='"${AB_USERCOND_Input_Table_Teradata_API__table_}"
   print -r -- 'AB_IS_LIVE_Input_Table_Teradata_API__table_='"${AB_IS_LIVE_Input_Table_Teradata_API__table_}"
   print -r -- 'AB_HAS_DATA_Flow_20='"${AB_HAS_DATA_Flow_20}"
   print -r -- 'AB_HAS_DATA_Flow_19='"${AB_HAS_DATA_Flow_19}"
   print -r -- 'AB_USERCOND_Gather_Extract_Logs_4='"${AB_USERCOND_Gather_Extract_Logs_4}"
   print -r -- 'AB_IS_LIVE_Gather_Extract_Logs_4='"${AB_IS_LIVE_Gather_Extract_Logs_4}"
   print -r -- 'AB_USERCOND_Input_Table_Teradata_Fast_Export__table_='"${AB_USERCOND_Input_Table_Teradata_Fast_Export__table_}"
   print -r -- 'AB_IS_LIVE_Input_Table_Teradata_Fast_Export__table_='"${AB_IS_LIVE_Input_Table_Teradata_Fast_Export__table_}"
   print -r -- 'AB_HAS_DATA_Flow_14='"${AB_HAS_DATA_Flow_14}"
   print -r -- 'AB_HAS_DATA_Flow_13='"${AB_HAS_DATA_Flow_13}"
   print -r -- 'AB_USERCOND_Gather_Extract_Logs_1='"${AB_USERCOND_Gather_Extract_Logs_1}"
   print -r -- 'AB_IS_LIVE_Gather_Extract_Logs_1='"${AB_IS_LIVE_Gather_Extract_Logs_1}"
   print -r -- 'AB_USERCOND_Replicate='"${AB_USERCOND_Replicate}"
   print -r -- 'AB_IS_LIVE_Replicate='"${AB_IS_LIVE_Replicate}"
   print -r -- 'AB_HAS_DATA_Flow_16='"${AB_HAS_DATA_Flow_16}"
   print -r -- 'AB_HAS_DATA_Flow_5='"${AB_HAS_DATA_Flow_5}"
   print -r -- 'AB_USERCOND_Conditional_Partition_by_Round_robin='"${AB_USERCOND_Conditional_Partition_by_Round_robin}"
   print -r -- 'AB_IS_LIVE_Conditional_Partition_by_Round_robin='"${AB_IS_LIVE_Conditional_Partition_by_Round_robin}"
   print -r -- 'AB_HAS_DATA_Flow_11='"${AB_HAS_DATA_Flow_11}"
   print -r -- 'AB_USERCOND_Retain_Flow_to_Flow='"${AB_USERCOND_Retain_Flow_to_Flow}"
   print -r -- 'AB_IS_LIVE_Retain_Flow_to_Flow='"${AB_IS_LIVE_Retain_Flow_to_Flow}"
   print -r -- 'AB_HAS_DATA_Flow_23='"${AB_HAS_DATA_Flow_23}"
   print -r -- 'AB_USERCOND_Conditional_Extract_Reformat='"${AB_USERCOND_Conditional_Extract_Reformat}"
   print -r -- 'AB_IS_LIVE_Conditional_Extract_Reformat='"${AB_IS_LIVE_Conditional_Extract_Reformat}"
   print -r -- 'AB_HAS_DATA_Flow_21='"${AB_HAS_DATA_Flow_21}"
   print -r -- 'AB_USERCOND_Deflate='"${AB_USERCOND_Deflate}"
   print -r -- 'AB_IS_LIVE_Deflate='"${AB_IS_LIVE_Deflate}"
   print -r -- 'AB_HAS_DATA_Flow_22='"${AB_HAS_DATA_Flow_22}"
   print -r -- 'AB_USERCOND_Output_File=1'
   print -r -- 'AB_IS_LIVE_Output_File=1'
   print -r -- 'AB_USERCOND_Send_From_Extract_Value_to_Rollup='"${AB_USERCOND_Send_From_Extract_Value_to_Rollup}"
   print -r -- 'AB_IS_LIVE_Send_From_Extract_Value_to_Rollup='"${AB_IS_LIVE_Send_From_Extract_Value_to_Rollup}"
   print -r -- 'AB_HAS_DATA_Flow_3='"${AB_HAS_DATA_Flow_3}"
   print -r -- 'AB_USERCOND_Get_Max_Value_for_Extract_Field='"${AB_USERCOND_Get_Max_Value_for_Extract_Field}"
   print -r -- 'AB_IS_LIVE_Get_Max_Value_for_Extract_Field='"${AB_IS_LIVE_Get_Max_Value_for_Extract_Field}"
   print -r -- 'AB_HAS_DATA_Flow_6='"${AB_HAS_DATA_Flow_6}"
   print -r -- 'AB_USERCOND_Last_Extract_Value_File_1='"${AB_USERCOND_Last_Extract_Value_File_1}"
   print -r -- 'AB_IS_LIVE_Last_Extract_Value_File_1='"${AB_IS_LIVE_Last_Extract_Value_File_1}"
   print -r -- 'AB_USERCOND_Send_Primer_Row_to_Reformat='"${AB_USERCOND_Send_Primer_Row_to_Reformat}"
   print -r -- 'AB_IS_LIVE_Send_Primer_Row_to_Reformat='"${AB_IS_LIVE_Send_Primer_Row_to_Reformat}"
   print -r -- 'AB_HAS_DATA_Flow_4='"${AB_HAS_DATA_Flow_4}"
   print -r -- 'AB_USERCOND_Update_Last_Extract_Value_File='"${AB_USERCOND_Update_Last_Extract_Value_File}"
   print -r -- 'AB_IS_LIVE_Update_Last_Extract_Value_File='"${AB_IS_LIVE_Update_Last_Extract_Value_File}"
   print -r -- 'AB_HAS_DATA_Flow_12='"${AB_HAS_DATA_Flow_12}"
   print -r -- 'AB_USERCOND_Last_Extract_Value_File='"${AB_USERCOND_Last_Extract_Value_File}"
   print -r -- 'AB_IS_LIVE_Last_Extract_Value_File='"${AB_IS_LIVE_Last_Extract_Value_File}"
   print -r -- 'AB_USERCOND_move_FEXP_LOGFILE='"${AB_USERCOND_move_FEXP_LOGFILE}"
   print -r -- 'AB_IS_LIVE_move_FEXP_LOGFILE='"${AB_IS_LIVE_move_FEXP_LOGFILE}"
fi

# Files:
mp ofile Output_File "$OUTPUT_FILE"
if [ X"${AB_IS_LIVE_Last_Extract_Value_File_1}" != X0 ]; then
   mp ofile Last_Extract_Value_File_1 'file:'"$LAST_EXTRACT_VALUE_FILE"
else
   :
fi
mp ifile Extract_Log_File 'file:'"$EXTRACT_LOG_FILE"
AB_PORT_Extract_Log_File_read=Extract_Log_File.read
AB_METADATA_Extract_Log_File_read=' -metadata metadata6'
mp ofile Record_Count_File 'file:'"$RECORD_COUNT_FILE"
if [ X"${AB_IS_LIVE_Last_Extract_Value_File}" != X0 ]; then
   mp ofile Last_Extract_Value_File 'file:'"$LAST_EXTRACT_VALUE_FILE"
else
   :
fi

# Components in phase 0:
if [ X"${AB_IS_LIVE_Input_Table_Generic_ODBC__table_}" != X0 ]; then
   mp itable Input_Table_Generic_ODBC__table_ "$AB_IDB_CONFIG" -select "${INPUT_TABLE_SEL}" -interface api -field_type_preference variable -limit 0 -ramp 0.0 -layout layout1
   AB_PORT_Input_Table_Generic_ODBC__table__read=Input_Table_Generic_ODBC__table_.read
   AB_METADATA_Input_Table_Generic_ODBC__table__read=' -metadata metadata1'
   AB_PORT_Input_Table_Generic_ODBC__table__log=Input_Table_Generic_ODBC__table_.log
   AB_METADATA_Input_Table_Generic_ODBC__table__log=' -metadata metadata2'
else
   :
fi
if [ X"${AB_IS_LIVE_Gather_Extract_Logs_3}" != X0 ]; then
   mp logger Gather_Extract_Logs_3 "$EXTRACT_LOG_FILE" Start End -layout layout2
else
   :
fi
if [ X"${AB_IS_LIVE_Input_Table_Oracle__table_}" != X0 ]; then
   mp itable Input_Table_Oracle__table_ "$AB_IDB_CONFIG" -select "${INPUT_TABLE_SEL}" -interface api -field_type_preference variable -ablocal_expr "$ABLOCAL" -oracle_max_kb "$ORA_MAX_KB" -parallel_mode rowid -limit 0 -ramp 0.0 -layout layout1
   AB_PORT_Input_Table_Oracle__table__read=Input_Table_Oracle__table_.read
   AB_METADATA_Input_Table_Oracle__table__read=' -metadata metadata1'
   AB_PORT_Input_Table_Oracle__table__log=Input_Table_Oracle__table_.log
   AB_METADATA_Input_Table_Oracle__table__log=' -metadata metadata2'
else
   :
fi
if [ X"${AB_IS_LIVE_Gather_Extract_Logs}" != X0 ]; then
   mp logger Gather_Extract_Logs "$EXTRACT_LOG_FILE" Start End -layout layout2
else
   :
fi
if [ X"${AB_IS_LIVE_Input_Table_Sqlserver__table_}" != X0 ]; then
   mp itable Input_Table_Sqlserver__table_ "$AB_IDB_CONFIG" -select "${INPUT_TABLE_SEL}" -interface api -field_type_preference variable -limit 0 -ramp 0.0 -layout layout1
   AB_PORT_Input_Table_Sqlserver__table__read=Input_Table_Sqlserver__table_.read
   AB_METADATA_Input_Table_Sqlserver__table__read=' -metadata metadata1'
   AB_PORT_Input_Table_Sqlserver__table__log=Input_Table_Sqlserver__table_.log
   AB_METADATA_Input_Table_Sqlserver__table__log=' -metadata metadata2'
else
   :
fi
if [ X"${AB_IS_LIVE_Gather_Extract_Logs_2}" != X0 ]; then
   mp logger Gather_Extract_Logs_2 "$EXTRACT_LOG_FILE" Start End -layout layout2
else
   :
fi
if [ X"${AB_IS_LIVE_Input_Table_Teradata_API__table_}" != X0 ]; then
   mp itable Input_Table_Teradata_API__table_ "$AB_IDB_CONFIG" -select "${INPUT_TABLE_SEL}" -interface api -field_type_preference variable -non_ansimode -limit 0 -ramp 0.0 -layout layout1
   AB_PORT_Input_Table_Teradata_API__table__read=Input_Table_Teradata_API__table_.read
   AB_METADATA_Input_Table_Teradata_API__table__read=' -metadata metadata1'
   AB_PORT_Input_Table_Teradata_API__table__log=Input_Table_Teradata_API__table_.log
   AB_METADATA_Input_Table_Teradata_API__table__log=' -metadata metadata2'
else
   :
fi
if [ X"${AB_IS_LIVE_Gather_Extract_Logs_4}" != X0 ]; then
   mp logger Gather_Extract_Logs_4 "$EXTRACT_LOG_FILE" Start End -layout layout2
else
   :
fi
if [ X"${AB_IS_LIVE_Input_Table_Teradata_Fast_Export__table_}" != X0 ]; then
   mp db-ter-fast-export Input_Table_Teradata_Fast_Export__table_ "$AB_IDB_CONFIG" -select "${INPUT_TABLE_SEL}" -interface FastExport -field_type_preference variable -brief -sleep "$FEXP_SLEEP" -tenacity "$FEXP_TENACITY" -sessions "$FEXP_SESSION_MAX_FIRST"' '"$FEXP_SESSION_MIN_SECOND" -logtab_name "$FEXP_LOGTAB" -logfile "$FEXP_LOGFILE" -axsmod_tracelevel None -limit 0 -ramp 0.0 -layout layout1
   AB_PORT_Input_Table_Teradata_Fast_Export__table__read=Input_Table_Teradata_Fast_Export__table_.read
   AB_METADATA_Input_Table_Teradata_Fast_Export__table__read=' -metadata metadata1'
   AB_PORT_Input_Table_Teradata_Fast_Export__table__log=Input_Table_Teradata_Fast_Export__table_.log
   AB_METADATA_Input_Table_Teradata_Fast_Export__table__log=' -metadata metadata2'
else
   :
fi
if [ X"${AB_IS_LIVE_Gather_Extract_Logs_1}" != X0 ]; then
   mp logger Gather_Extract_Logs_1 "$EXTRACT_LOG_FILE" Start End -layout layout2
else
   :
fi
if [ X"${AB_IS_LIVE_Replicate}" != X0 ]; then
   mp broadcast Replicate -layout layout1
   AB_PORT_Replicate_out=Replicate.out
   AB_METADATA_Replicate_out=' -metadata metadata1'
else
   let AB_PORT_HAS_DATA="AB_HAS_DATA_Flow_14"
   if [ X"${AB_PORT_HAS_DATA}" != X0 ]; then
      AB_PORT_Replicate_out="${AB_PORT_Input_Table_Teradata_Fast_Export__table__read}"
      AB_METADATA_Replicate_out="${AB_METADATA_Input_Table_Teradata_Fast_Export__table__read}"
   fi
   let AB_PORT_HAS_DATA="AB_HAS_DATA_Flow_20"
   if [ X"${AB_PORT_HAS_DATA}" != X0 ]; then
      AB_PORT_Replicate_out="${AB_PORT_Input_Table_Teradata_API__table__read}"
      AB_METADATA_Replicate_out="${AB_METADATA_Input_Table_Teradata_API__table__read}"
   fi
   let AB_PORT_HAS_DATA="AB_HAS_DATA_Flow_2"
   if [ X"${AB_PORT_HAS_DATA}" != X0 ]; then
      AB_PORT_Replicate_out="${AB_PORT_Input_Table_Oracle__table__read}"
      AB_METADATA_Replicate_out="${AB_METADATA_Input_Table_Oracle__table__read}"
   fi
   let AB_PORT_HAS_DATA="AB_HAS_DATA_Flow_8"
   if [ X"${AB_PORT_HAS_DATA}" != X0 ]; then
      AB_PORT_Replicate_out="${AB_PORT_Input_Table_Sqlserver__table__read}"
      AB_METADATA_Replicate_out="${AB_METADATA_Input_Table_Sqlserver__table__read}"
   fi
   let AB_PORT_HAS_DATA="AB_HAS_DATA_Flow_18"
   if [ X"${AB_PORT_HAS_DATA}" != X0 ]; then
      AB_PORT_Replicate_out="${AB_PORT_Input_Table_Generic_ODBC__table__read}"
      AB_METADATA_Replicate_out="${AB_METADATA_Input_Table_Generic_ODBC__table__read}"
   fi
   :
fi
if [ X"${AB_IS_LIVE_Conditional_Partition_by_Round_robin}" != X0 ]; then
   mp roundrobin-partition Conditional_Partition_by_Round_robin 1 -layout layout1
   AB_PORT_Conditional_Partition_by_Round_robin_out=Conditional_Partition_by_Round_robin.out
   AB_METADATA_Conditional_Partition_by_Round_robin_out=' -metadata metadata1'
else
   AB_PORT_Conditional_Partition_by_Round_robin_out="${AB_PORT_Replicate_out}"
   AB_METADATA_Conditional_Partition_by_Round_robin_out="${AB_METADATA_Replicate_out}"
   :
fi
if [ X"${AB_IS_LIVE_Retain_Flow_to_Flow}" != X0 ]; then
   mp broadcast Retain_Flow_to_Flow -layout Output_File
   AB_PORT_Retain_Flow_to_Flow_out=Retain_Flow_to_Flow.out
   AB_METADATA_Retain_Flow_to_Flow_out=' -metadata metadata1'
else
   AB_PORT_Retain_Flow_to_Flow_out="${AB_PORT_Conditional_Partition_by_Round_robin_out}"
   AB_METADATA_Retain_Flow_to_Flow_out="${AB_METADATA_Conditional_Partition_by_Round_robin_out}"
   :
fi
if [ X"${AB_IS_LIVE_Conditional_Extract_Reformat}" != X0 ]; then
   mp reformat-transform Conditional_Extract_Reformat -limit 0 -ramp 0.0 -layout Output_File
   let AB_DO_ADD_PORT="AB_HAS_DATA_Flow_21"
   if [ X"${AB_DO_ADD_PORT}" != X0 ]; then
      mp add-port Conditional_Extract_Reformat.out.out0 ${REFORMAT_TRANS_FILE:+"$REFORMAT_TRANS_FILE"}
   fi
   AB_PORT_Conditional_Extract_Reformat_out_out0=Conditional_Extract_Reformat.out.out0
   AB_METADATA_Conditional_Extract_Reformat_out_out0=' -metadata metadata3'
else
   AB_PORT_Conditional_Extract_Reformat_out_out0="${AB_PORT_Retain_Flow_to_Flow_out}"
   AB_METADATA_Conditional_Extract_Reformat_out_out0="${AB_METADATA_Retain_Flow_to_Flow_out}"
   :
fi
if [ X"${AB_IS_LIVE_Deflate}" != X0 ]; then
   mp broadcast Deflate -compression "$Deflate__compression" -layout Output_File
   AB_PORT_Deflate_out=Deflate.out
   AB_METADATA_Deflate_out=' -metadata metadata4'
else
   AB_PORT_Deflate_out="${AB_PORT_Conditional_Extract_Reformat_out_out0}"
   AB_METADATA_Deflate_out="${AB_METADATA_Conditional_Extract_Reformat_out_out0}"
   :
fi
if [ X"${AB_IS_LIVE_Send_From_Extract_Value_to_Rollup}" != X0 ]; then
   mp generate Send_From_Extract_Value_to_Rollup 1 -expression $ROLLUP_FIELD '$FROM_EXTRACT_VALUE' -layout Last_Extract_Value_File_1
   AB_PORT_Send_From_Extract_Value_to_Rollup_out=Send_From_Extract_Value_to_Rollup.out
   AB_METADATA_Send_From_Extract_Value_to_Rollup_out=' -metadata metadata1'
else
   :
fi
if [ X"${AB_IS_LIVE_Get_Max_Value_for_Extract_Field}" != X0 ]; then
   mp hash-rollup Get_Max_Value_for_Extract_Field '{}' "${_AB_PROXY_DIR}"'/Get_Max_Value_for_Extract_Field-7.xfr' -max-core 67108864 -limit 0 -ramp 0.0 -layout Last_Extract_Value_File_1
   AB_PORT_Get_Max_Value_for_Extract_Field_out=Get_Max_Value_for_Extract_Field.out
   AB_METADATA_Get_Max_Value_for_Extract_Field_out=' -metadata metadata5'
else
   :
fi
mp checkpoint 0

# Components in phase 1:
mp reformat-transform Reformat -select 'string_index(line, "unload|rows|Rows unloaded:") > 0 || string_index(line, "UTY8722") > 0' -limit 0 -ramp 0.0 -layout Record_Count_File
mp add-port Reformat.out.out0 ${_AB_PROXY_DIR:+"$_AB_PROXY_DIR"}'/Reformat-10.xfr'
AB_PORT_Reformat_out_out0=Reformat.out.out0
AB_METADATA_Reformat_out_out0=' -metadata metadata7'
mp hash-rollup Rollup_Record_Counts '{}' "${_AB_PROXY_DIR}"'/Rollup_Record_Counts-12.xfr' -max-core 67108864 -limit 0 -ramp 0.0 -layout Record_Count_File
AB_PORT_Rollup_Record_Counts_out=Rollup_Record_Counts.out
AB_METADATA_Rollup_Record_Counts_out=' -metadata metadata8'
if [ X"${AB_IS_LIVE_move_FEXP_LOGFILE}" != X0 ]; then
   mp filter move_FEXP_LOGFILE $move_FEXP_LOGFILE__commandline -layout layout3
else
   :
fi
mp checkpoint 1

# Components in phase 2:
if [ X"${AB_IS_LIVE_Send_Primer_Row_to_Reformat}" != X0 ]; then
   mp generate Send_Primer_Row_to_Reformat 1 -layout layout4
   AB_PORT_Send_Primer_Row_to_Reformat_out=Send_Primer_Row_to_Reformat.out
   AB_METADATA_Send_Primer_Row_to_Reformat_out=' -metadata metadata9'
else
   :
fi
if [ X"${AB_IS_LIVE_Update_Last_Extract_Value_File}" != X0 ]; then
   mp reformat-transform Update_Last_Extract_Value_File -limit 0 -ramp 0.0 -layout layout4
   let AB_DO_ADD_PORT="AB_HAS_DATA_Flow_12"
   if [ X"${AB_DO_ADD_PORT}" != X0 ]; then
      mp add-port Update_Last_Extract_Value_File.out.out0 ${_AB_PROXY_DIR:+"$_AB_PROXY_DIR"}'/Update_Last_Extract_Value_File-15.xfr'
   fi
   AB_PORT_Update_Last_Extract_Value_File_out_out0=Update_Last_Extract_Value_File.out.out0
   AB_METADATA_Update_Last_Extract_Value_File_out_out0=' -metadata metadata5'
else
   :
fi

# Flows for Entire Graph:
let AB_FLOW_CONDITION="(AB_IS_LIVE_Gather_Extract_Logs_3) && (AB_HAS_DATA_Flow_17)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp fan-in-flow Flow_17 "${AB_PORT_Input_Table_Generic_ODBC__table__log}" Gather_Extract_Logs_3.in${AB_METADATA_Input_Table_Generic_ODBC__table__log}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Gather_Extract_Logs) && (AB_HAS_DATA_Flow_1)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp fan-in-flow Flow_1 "${AB_PORT_Input_Table_Oracle__table__log}" Gather_Extract_Logs.in${AB_METADATA_Input_Table_Oracle__table__log}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Gather_Extract_Logs_2) && (AB_HAS_DATA_Flow_15)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp fan-in-flow Flow_15 "${AB_PORT_Input_Table_Sqlserver__table__log}" Gather_Extract_Logs_2.in${AB_METADATA_Input_Table_Sqlserver__table__log}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Gather_Extract_Logs_4) && (AB_HAS_DATA_Flow_19)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp fan-in-flow Flow_19 "${AB_PORT_Input_Table_Teradata_API__table__log}" Gather_Extract_Logs_4.in${AB_METADATA_Input_Table_Teradata_API__table__log}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Gather_Extract_Logs_1) && (AB_HAS_DATA_Flow_13)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp fan-in-flow Flow_13 "${AB_PORT_Input_Table_Teradata_Fast_Export__table__log}" Gather_Extract_Logs_1.in${AB_METADATA_Input_Table_Teradata_Fast_Export__table__log}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Replicate) && (AB_HAS_DATA_Flow_14)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_14 "${AB_PORT_Input_Table_Teradata_Fast_Export__table__read}" Replicate.in${AB_METADATA_Input_Table_Teradata_Fast_Export__table__read}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Replicate) && (AB_HAS_DATA_Flow_20)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_20 "${AB_PORT_Input_Table_Teradata_API__table__read}" Replicate.in${AB_METADATA_Input_Table_Teradata_API__table__read}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Replicate) && (AB_HAS_DATA_Flow_2)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_2 "${AB_PORT_Input_Table_Oracle__table__read}" Replicate.in${AB_METADATA_Input_Table_Oracle__table__read}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Replicate) && (AB_HAS_DATA_Flow_8)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_8 "${AB_PORT_Input_Table_Sqlserver__table__read}" Replicate.in${AB_METADATA_Input_Table_Sqlserver__table__read}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Replicate) && (AB_HAS_DATA_Flow_18)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_18 "${AB_PORT_Input_Table_Generic_ODBC__table__read}" Replicate.in${AB_METADATA_Input_Table_Generic_ODBC__table__read}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Conditional_Partition_by_Round_robin) && (AB_HAS_DATA_Flow_16)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_16 "${AB_PORT_Replicate_out}" Conditional_Partition_by_Round_robin.in${AB_METADATA_Replicate_out}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Retain_Flow_to_Flow) && (AB_HAS_DATA_Flow_11)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp all-to-all-flow Flow_11 "${AB_PORT_Conditional_Partition_by_Round_robin_out}" Retain_Flow_to_Flow.in${AB_METADATA_Conditional_Partition_by_Round_robin_out}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Conditional_Extract_Reformat) && (AB_HAS_DATA_Flow_23)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_23 "${AB_PORT_Retain_Flow_to_Flow_out}" Conditional_Extract_Reformat.in${AB_METADATA_Retain_Flow_to_Flow_out}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Deflate) && (AB_HAS_DATA_Flow_21)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_21 "${AB_PORT_Conditional_Extract_Reformat_out_out0}" Deflate.in${AB_METADATA_Conditional_Extract_Reformat_out_out0}
fi
let AB_FLOW_CONDITION="AB_HAS_DATA_Flow_22"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_22 "${AB_PORT_Deflate_out}" Output_File.write${AB_METADATA_Deflate_out}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Get_Max_Value_for_Extract_Field) && (AB_HAS_DATA_Flow_5)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp fan-in-flow Flow_5 "${AB_PORT_Replicate_out}" Get_Max_Value_for_Extract_Field.in${AB_METADATA_Replicate_out}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Get_Max_Value_for_Extract_Field) && (AB_HAS_DATA_Flow_3)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_3 "${AB_PORT_Send_From_Extract_Value_to_Rollup_out}" Get_Max_Value_for_Extract_Field.in${AB_METADATA_Send_From_Extract_Value_to_Rollup_out}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Last_Extract_Value_File_1) && (AB_HAS_DATA_Flow_6)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_6 "${AB_PORT_Get_Max_Value_for_Extract_Field_out}" Last_Extract_Value_File_1.write${AB_METADATA_Get_Max_Value_for_Extract_Field_out}
fi
mp straight-flow Flow_7 "${AB_PORT_Extract_Log_File_read}" Reformat.in${AB_METADATA_Extract_Log_File_read}
mp straight-flow Flow_9 "${AB_PORT_Reformat_out_out0}" Rollup_Record_Counts.in${AB_METADATA_Reformat_out_out0}
mp straight-flow Flow_10 "${AB_PORT_Rollup_Record_Counts_out}" Record_Count_File.write${AB_METADATA_Rollup_Record_Counts_out}
let AB_FLOW_CONDITION="(AB_IS_LIVE_Update_Last_Extract_Value_File) && (AB_HAS_DATA_Flow_4)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_4 "${AB_PORT_Send_Primer_Row_to_Reformat_out}" Update_Last_Extract_Value_File.in${AB_METADATA_Send_Primer_Row_to_Reformat_out}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_Last_Extract_Value_File) && (AB_HAS_DATA_Flow_12)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_12 "${AB_PORT_Update_Last_Extract_Value_File_out_out0}" Last_Extract_Value_File.write${AB_METADATA_Update_Last_Extract_Value_File_out_out0}
fi

if [ X"${AB_VERBOSE_CONDITIONS}" != X"" ]; then
   print -r -- 'Generated graph:'
   mp show
fi
unset AB_COMM_WAIT
export AB_TRACKING_GRAPH_THUMBPRINT;AB_TRACKING_GRAPH_THUMBPRINT=7551897
mp run
mpjret=$?
unset AB_COMM_WAIT
unset AB_TRACKING_GRAPH_THUMBPRINT
mp reset
m_rmcatalog > /dev/null 2>&1
export XX_CATALOG;XX_CATALOG="${SAVED_CATALOG}"
export AB_CATALOG;AB_CATALOG="${SAVED_CATALOG}"

#+Script End+  ==================== Edits in this section are preserved.
#+End Script End+  ====================

exit $mpjret
