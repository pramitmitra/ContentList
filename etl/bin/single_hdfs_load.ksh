#! /bin/ksh
# Script generated by software licensed from Ab Initio.
# Use and disclosure are subject to Ab Initio confidentiality and license terms.
export AB_HOME;AB_HOME=${AB_HOME:-/legato/softlib/abinitio/abinitio-V3-1-4}
export MPOWERHOME;MPOWERHOME="$AB_HOME"
export AB_COMPONENTS;AB_COMPONENTS="$AB_HOME"'/Projects/root/components'
export PATH
typeset _ab_uname=`uname`
case "$_ab_uname" in
Windows_* )
    PATH="$AB_HOME/bin;$PATH" ;;
CYGWIN_* )
    PATH="`cygpath "$AB_HOME"`/bin:/usr/local/bin:/usr/bin:/bin:$PATH" ;;
* )
    PATH="$AB_HOME/bin:$PATH" ;;
esac
unset ENV
export AB_REPORT;AB_REPORT=${AB_REPORT:-'monitor=300 processes scroll=true'}
unset GDE_EXECUTION

export AB_COMPATIBILITY;AB_COMPATIBILITY=3.1.4.4

# Deployed execution script for graph "single_hdfs_load", compiled at Friday, October 04, 2013 11:15:56 using GDE version 3.0.3.1
export AB_JOB;AB_JOB=${AB_JOB_PREFIX:-""}single_hdfs_load
# Begin Ab Initio shell utility functions

: ${_ab_uname:=$(uname)}

function __AB_INVOKE_PROJECT
{
  typeset _AB_PROJECT_KSH="$1" ; shift
  typeset _AB_PROJECT_DIR="$1" ; shift
  typeset _AB_DEFINE_OR_EXECUTE="$1" ; shift
  typeset _AB_START_OR_END="$1" ; shift
  # Check that the project exists:
  if [ ! -r "$_AB_PROJECT_KSH" ] ; then
    print -r -u2 Warning: Cannot find common sandbox script: "$_AB_PROJECT_KSH"
    if [ ! -z "${_AB_CALLING_PROJECT:=}" ] ; then
      print -r -u2 Please check the common sandbox settings for the calling project: "$_AB_CALLING_PROJECT"
    fi
  fi
  if [ $# -gt 0 ] ; then
    . "$_AB_PROJECT_KSH" "$_AB_PROJECT_DIR" "$_AB_DEFINE_OR_EXECUTE" "$_AB_START_OR_END"  "$@"
  else
    . "$_AB_PROJECT_KSH" "$_AB_PROJECT_DIR" "$_AB_DEFINE_OR_EXECUTE" "$_AB_START_OR_END" 
  fi;
}

function __AB_DOTIT
{
  if [ $# -gt 0 ] ; then
    .  "$@"
  fi
}

function __AB_QUOTEIT {
  typeset queue q qq qed lotsaqs s trail
  q="'"
  qq='"'
  if [ X"$1" = X"" ] ; then
    print $q$q
    return
  fi
  lotsaqs=${q}${qq}${q}${qq}${q}
  if [ ${#1} -ge 10000 ]; then
    print -r -- "$1" | sed "s/$q/$lotsaqs/g; 1s/^/$q/; \$s/\$/$q/"
  else
    queue=${1%$q}
    if [ X"$queue" != X"$1" ] ; then
      trail="${qq}${q}${qq}" 
    else 
      trail=""
    fi
    oldIFS="$IFS"
    IFS=$q
    set -- $queue
    IFS="$oldIFS"
    print -rn "$q$1"
    shift
    for s; do
      print -rn "$lotsaqs$s"
    done
    print -r $q$trail
  fi
}

function __AB_dirname {
    case $_ab_uname in
    Windows_* | CYGWIN_* )
        typeset d='' p="$1"
        # Strip drive letter colon, if present, and put it into d.
        case $p in
        [A-Za-z]:* )
            d=${p%%:*}:
            p=${p#??}
            ;;
        esac
        # Remove trailing separators, though not the last character in the
        # pathname.
        while : true; do
            case $p in
            ?*[/\\] )
                p=${p%[/\\]} ;;
            * )
                break ;;
            esac
        done
        if [[ "$p" = ?*[/\\]* ]] ; then
            print -r -- "$d${p%[/\\]*}"
        elif [[ "$p" = [/\\]* ]] ; then
            print "$d/"
        else
            print "$d." 
        fi
        ;;
    * ) # Unix
        typeset p="$1"
        # Remove trailing separators, though not the last character in the
        # pathname.
        while : true; do
            case $p in
            ?*/ )
                p="${p%/}" ;;
            * )
                break ;;
            esac
        done
        case $p in
        ?*/* )
            print -r -- "${p%/*}" ;;
        /* )
            print / ;;
        * )
            print . ;;
        esac
        ;;
    esac
}

function __AB_concat_pathname {
    case $_ab_uname in
    Windows_* | CYGWIN_* )
        # Does not handle all cases of concatenating partially absolute
        # pathnames, those with only one of a drive letter or an initial
        # separator.
        case $2 in
        [/\\]* | [A-Za-z]:* )
            print -r -- "$2"
            ;;
        * )
            case $1 in
            # Assume that empty string means ".".  Avoid adding a
            # redundant separator.
            '' | *[/\\] )
                print -r -- "$1$2" ;;
            * )
                print -r -- "$1/$2" ;;
            esac
            ;;
        esac
        ;;
    * ) # Unix
        case $2 in
        /* )
            print -r -- "$2"
            ;;
        * )
            case $1 in
            # Assume that empty string means ".".  Avoid adding a
            # redundant separator.
            '' | */ )
                print -r -- "$1$2" ;;
            * )
                print -r -- "$1/$2" ;;
            esac
            ;;
        esac
        ;;
    esac
}

function __AB_COND {
if [ X"$1" = X0  -o X"$1" = Xfalse -o X"$1" = XFalse -o X"$1" = XF -o X"$1" = Xf ] ; then
  print "0"
else
  print "1"
fi
}

# End Ab Initio shell utility functions
export AB_GRAPH_NAME;AB_GRAPH_NAME=single_hdfs_load

# Host Setup Commands:
. /dw/etl/mstr_cfg/etlenv.setup
_AB_PROXY_DIR=single_hdfs_load-ProxyDir-$$
rm -rf "${_AB_PROXY_DIR}"
mkdir "${_AB_PROXY_DIR}"
print -r -- "" > "${_AB_PROXY_DIR}"'/GDE-Parameters'
function __AB_CLEANUP_PROXY_FILES
{
   rm -rf "${_AB_PROXY_DIR}"
   rm -rf "${AB_EXTERNAL_PROXY_DIR}"
   return
}
trap '__AB_CLEANUP_PROXY_FILES' EXIT
# Work around pdksh bug: the EXIT handler is not executed upon a signal.
trap '_AB_status=$?; __AB_CLEANUP_PROXY_FILES; exit $_AB_status' HUP INT QUIT TERM
if [ $# -gt 0 -a X"$1" = X"-help" ]; then
print -r -- 'Usage: single_hdfs_load.ksh <ETL_ID> <JOB_ENV> <INPUT_DML_FILENAME> -UOW_FROM <UOW_FROM> -UOW_TO <UOW_TO>'
exit 1
fi

# Command Line Processing
function _AB_PARSE_ARGUMENTS {
   unset ETL_ID
   unset JOB_ENV
   unset INPUT_DML_FILENAME
   unset UOW_FROM
   unset UOW_TO
   _ab_index_var=0
   if [ $# -gt 0 ]; then
      export ETL_ID;      ETL_ID="${1}"
      let _ab_index_var=_ab_index_var+1
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      shift
   fi
   if [ $# -gt 0 ]; then
      export JOB_ENV;      JOB_ENV="${1}"
      let _ab_index_var=_ab_index_var+1
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      shift
   fi
   if [ $# -gt 0 ]; then
      export INPUT_DML_FILENAME;      INPUT_DML_FILENAME="${1}"
      let _ab_index_var=_ab_index_var+1
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      shift
   fi
   while [ $# -gt 0 ]; do
   _ab_kwd="${1}"
   let _ab_index_var=_ab_index_var+1
   shift
   case ${_ab_kwd} in
     -UOW_FROM )
      export UOW_FROM;      UOW_FROM="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -UOW_TO )
      export UOW_TO;      UOW_TO="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -CNDTL_COMPRESSION )
      CNDTL_COMPRESSION="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -CNDTL_COMPRESSION_SFX )
      CNDTL_COMPRESSION_SFX="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -INPUT_FILE )
      export INPUT_FILE;      INPUT_FILE="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -OUTPUT_FILE )
      export OUTPUT_FILE;      OUTPUT_FILE="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
     -HADOOP_CONN )
      HADOOP_CONN="${1}"
      _AB_USED_ARGUMENTS[_ab_index_var]=1
      _AB_USED_ARGUMENTS[_ab_index_var+1]=1
      let _ab_index_var=_ab_index_var+1
      shift
      ;;
   * )
      if [ X"${_AB_USED_ARGUMENTS[_ab_index_var]}" != X1 ]; then
         print -r -- 'Unexpected command line argument found: '"${_ab_kwd}"
         print -r -- 'Usage: single_hdfs_load.ksh <ETL_ID> <JOB_ENV> <INPUT_DML_FILENAME> -UOW_FROM <UOW_FROM> -UOW_TO <UOW_TO>'
         exit 1
      fi
   esac
   done
}
if [ $# -gt 0 ]; then
   _AB_PARSE_ARGUMENTS "$@"
else
   _AB_PARSE_ARGUMENTS
fi

if [ X"${ETL_ID:-}" = X"" ]; then
   print -r -- 'Required parameter ETL_ID undefined'
   print -r -- 'Usage: single_hdfs_load.ksh <ETL_ID> <JOB_ENV> <INPUT_DML_FILENAME> -UOW_FROM <UOW_FROM> -UOW_TO <UOW_TO>'
   exit 1
fi

if [ X"${JOB_ENV:-}" = X"" ]; then
   print -r -- 'Required parameter JOB_ENV undefined'
   print -r -- 'Usage: single_hdfs_load.ksh <ETL_ID> <JOB_ENV> <INPUT_DML_FILENAME> -UOW_FROM <UOW_FROM> -UOW_TO <UOW_TO>'
   exit 1
fi
export INPUT_DML_FILENAME;INPUT_DML_FILENAME=${INPUT_DML_FILENAME:-"$ETL_ID"'.read.dml'}
export UOW_FROM;UOW_FROM=${UOW_FROM:-""}
export UOW_TO;UOW_TO=${UOW_TO:-""}
export UOW_DATE;UOW_DATE=$(print $UOW_TO | cut -c1-8)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter UOW_DATE of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export OVRD_DML_FILENAME;OVRD_DML_FILENAME="$ETL_ID"'.read.ovrd.dml'
export UOW_APPEND;UOW_APPEND=$(if [[ -n $UOW_TO ]]
  then
    print ".$UOW_TO"
  else
    print ""
  fi
 )
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter UOW_APPEND of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export JOB_TYPE;JOB_TYPE=hdfs_load
export DW_CFG;DW_CFG="$DW_CFG"
export DW_DML;DW_DML="$DW_DML"
export DW_EXE;DW_EXE="$DW_EXE"
export ETL_CFG_FILE;ETL_CFG_FILE="$DW_CFG"'/'"$ETL_ID"'.cfg'
export SUBJECT_AREA;SUBJECT_AREA=${ETL_ID%%.*}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter SUBJECT_AREA of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export TABLE_ID;TABLE_ID=${ETL_ID##*.}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter TABLE_ID of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export AB_JOB;AB_JOB=$(if [ $ETL_ENV ]
then
   print $AB_JOB.$ETL_ID.$ETL_ENV.$JOB_ENV
else
   print $AB_JOB.$ETL_ID.$JOB_ENV
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter AB_JOB of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export DW_SA_ARC;DW_SA_ARC="$DW_ARC"'/'"$JOB_ENV"'/'"$SUBJECT_AREA"
export DW_SA_DAT;DW_SA_DAT="$DW_DAT"'/'"$JOB_ENV"'/'"$SUBJECT_AREA"
export DW_SA_IN;DW_SA_IN="$DW_IN"'/'"$JOB_ENV"'/'"$SUBJECT_AREA"
export DW_SA_LOG;DW_SA_LOG=${DW_SA_LOG:-$DW_LOG/$JOB_ENV/$SUBJECT_AREA}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter DW_SA_LOG of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export DW_SA_TMP;DW_SA_TMP="$DW_TMP"'/'"$JOB_ENV"'/'"$SUBJECT_AREA"
export FILE_DATETIME;FILE_DATETIME=${CURR_DATETIME:-$(date '+%Y%m%d-%H%M%S')}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter FILE_DATETIME of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export IN_DIR;IN_DIR=${IN_DIR:-$(grep "^IN_DIR\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE/$JOB_ENV/$SUBJECT_AREA)}
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter IN_DIR of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export INPUT_DML;INPUT_DML=$(if [[ $USE_OVRD_DML -eq 1 ]]
  then
      print $DW_DML/$OVRD_DML_FILENAME
  else
      print $DW_DML/$INPUT_DML_FILENAME
  fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter INPUT_DML of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export BATCH_SEQ_NUM;BATCH_SEQ_NUM=$(( $(<$DW_SA_DAT/$TABLE_ID.hdfs_load.batch_seq_num.dat) + 1))
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter BATCH_SEQ_NUM of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export MIN_BATCH_SEQ_NUM;MIN_BATCH_SEQ_NUM="$BATCH_SEQ_NUM"
export MAX_BATCH_SEQ_NUM;MAX_BATCH_SEQ_NUM=$($DW_EXE/get_batch_seq_num.ksh)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter MAX_BATCH_SEQ_NUM of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
CNDTL_COMPRESSION=$(grep "^CNDTL_COMPRESSION\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print ${VALUE:-0})
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CNDTL_COMPRESSION of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
CNDTL_COMPRESSION_SFX=$(grep "^CNDTL_COMPRESSION_SFX\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print $VALUE)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CNDTL_COMPRESSION_SFX of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export INPUT_FILE;INPUT_FILE=$(INPUT_FILE_TMP=""
if [ $CNDTL_COMPRESSION != 1 ]
then
   CNDTL_COMPRESSION_SFX=""
fi

FIRST_FILE=1

if [[ -n $UOW_TO ]]
then
   typeset -i UOW_ITER_DATE
   typeset -Z2 UOW_ITER_HH
   typeset -i UOW_ITER_DATEHH
   UOW_TO_DATEHH=$UOW_TO_DATE$UOW_TO_HH
   UOW_ITER_DATE=$UOW_FROM_DATE
   UOW_ITER_HH=$UOW_FROM_HH
   UOW_ITER_DATEHH=$UOW_ITER_DATE$UOW_FROM_HH
   UOW_IN_DIR=${IN_DIR%/$UOW_TO_DATE/$UOW_TO_HH/$UOW_TO_MI/$UOW_TO_SS}

   while [[ $UOW_ITER_DATEHH -le $UOW_TO_DATEHH ]]
   do
      if [[ $UOW_ITER_DATE -lt $UOW_TO_DATE ]]
      then
         UOW_ITER_HH_TO=23
      else
         UOW_ITER_HH_TO=$UOW_TO_HH
      fi
      while [[ $UOW_ITER_HH -le $UOW_ITER_HH_TO ]]
      do
         if [ $EXTRACT_PROCESS_TYPE = 'L' ]
         then
            for SRC_LIS_TMP in $(find $DW_DAT/extract/$SUBJECT_AREA/$ETL_ID.sources.lis.$UOW_ITER_DATE$UOW_ITER_HH[0-5][0-9][0-5][0-9] -type f -prune 2>/dev/null)
            do
               UOW_TMP=${SRC_LIS_TMP##*.}
               if [[ $UOW_TMP != $UOW_FROM ]]
               then
                  UOW_TMP_MI=$(print $UOW_TMP | cut -c11-12)
                  UOW_TMP_SS=$(print $UOW_TMP | cut -c13-14)
                  IN_DIR_TMP=$UOW_IN_DIR/$UOW_ITER_DATE/$UOW_ITER_HH/$UOW_TMP_MI/$UOW_TMP_SS
                  while read FILE_ID DATA_FILENAME OLD_FILENAME DONE_FILENAME
                  do
                     if [ $PARALLEL_FILE_LOAD = 1 ]
                     then
                        if [ $FIRST_FILE = 1 ]
                        then
                           eval print $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX $OLD_FILENAME > $INPUT_FILE_FILE
                           FIRST_FILE=0
                        else
                           eval print $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX $OLD_FILENAME >> $INPUT_FILE_FILE
                        fi
                     else
                        INPUT_FILE_TMP="$INPUT_FILE_TMP $(eval print $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX)"
                     fi
                  done < $SRC_LIS_TMP
               fi
            done
         else
            for IN_DIR_TMP in $(find $UOW_IN_DIR/$UOW_ITER_DATE/$UOW_ITER_HH/[0-5][0-9]/[0-5][0-9] -type d -prune 2>/dev/null)
            do
               if [[ "$IN_DIR_TMP" != "$UOW_IN_DIR/$UOW_FROM_DATE/$UOW_FROM_HH/$UOW_FROM_MI/$UOW_FROM_SS" ]]
               then
                  if [ $USE_DISTR_TABLE = 1 ]
                  then
                     read TABLE_NAME DATA_FILENAME PARAM < $DW_CFG/$ETL_ID.sources.lis
                     while read FILE_ID DBC_FILE
                     do
                        if [ $PARALLEL_FILE_LOAD = 1 ]
                        then
                           if [ $FIRST_FILE = 1 ]
                           then
                              if [ -f $(eval print ${IN_DIR_TMP}/.${DATA_FILENAME}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                              then
                                 eval print $(m_expand -native $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX) | tr ' ' '\012' > $EXPANDED_MULTIFILE_FILE
                                 FIRST_PASS=1
                                 while read EXPANDED_FILENAME
                                 do
                                    if [ $FIRST_PASS = 1 ]
                                    then
                                        eval print $EXPANDED_FILENAME $DATA_FILENAME > $INPUT_FILE_FILE
                                        FIRST_PASS=0
                                    else
                                        eval print $EXPANDED_FILENAME $DATA_FILENAME >> $INPUT_FILE_FILE
                                    fi
                                 done <  $EXPANDED_MULTIFILE_FILE
                                 rm $EXPANDED_MULTIFILE_FILE
                              else
                                 eval print $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX $DATA_FILENAME > $INPUT_FILE_FILE
                              fi
                              FIRST_FILE=0
                           else
                              if [ -f $(eval print ${IN_DIR_TMP}/.${DATA_FILENAME}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                              then
                                 eval print $(m_expand -native $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX) | tr ' ' '\012' > $EXPANDED_MULTIFILE_FILE
                                 while read EXPANDED_FILENAME
                                 do
                                    eval print $EXPANDED_FILENAME $DATA_FILENAME >> $INPUT_FILE_FILE
                                 done <  $EXPANDED_MULTIFILE_FILE
                                 rm $EXPANDED_MULTIFILE_FILE
                              else
                                 eval print $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX $DATA_FILENAME >> $INPUT_FILE_FILE
                              fi
                           fi
                        else
                           if [ -f $(eval print ${IN_DIR_TMP}/.${DATA_FILENAME}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                           then
                              INPUT_FILE_TMP="$INPUT_FILE_TMP $(eval print $(m_expand $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX))"
                           else
                              INPUT_FILE_TMP="$INPUT_FILE_TMP $(eval print $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX)"
                           fi
                        fi
                     done < $DW_CFG/$DISTR_TABLE_LIS_FILE.sources.lis
                  else
                     while read FILE_ID DBC_FILE PARALLEL_NUM TABLE_NAME DATA_FILENAME PARAM
                     do
                        if [ $PARALLEL_FILE_LOAD = 1 ]
                        then
                           if [ $FIRST_FILE = 1 ]
                           then
                              if [ -f $(eval print ${IN_DIR_TMP}/.${DATA_FILENAME}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                              then
                                 eval print $(m_expand -native $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX) | tr ' ' '\012' > $EXPANDED_MULTIFILE_FILE
                                 FIRST_PASS=1
                                 while read EXPANDED_FILENAME
                                 do
                                    if [ $FIRST_PASS = 1 ]
                                    then
                                       eval print $EXPANDED_FILENAME $DATA_FILENAME > $INPUT_FILE_FILE
                                       FIRST_PASS=0
                                    else
                                       eval print $EXPANDED_FILENAME $DATA_FILENAME >> $INPUT_FILE_FILE
                                    fi
                                 done <  $EXPANDED_MULTIFILE_FILE
                                 rm $EXPANDED_MULTIFILE_FILE
                              else
                                 eval print $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX $DATA_FILENAME > $INPUT_FILE_FILE
                              fi
                              FIRST_FILE=0
                           else
                              if [ -f $(eval print ${IN_DIR_TMP}/.${DATA_FILENAME}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                              then
                                 eval print $(m_expand -native $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX) | tr ' ' '\012' > $EXPANDED_MULTIFILE_FILE
                                 while read EXPANDED_FILENAME
                                 do
                                    eval print $EXPANDED_FILENAME $DATA_FILENAME >> $INPUT_FILE_FILE
                                 done <  $EXPANDED_MULTIFILE_FILE
                                 rm $EXPANDED_MULTIFILE_FILE
                              else
                                 eval print $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX $DATA_FILENAME >> $INPUT_FILE_FILE
                              fi
                           fi
                        else
                           if [ -f $(eval print ${IN_DIR_TMP}/.${DATA_FILENAME}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                           then
                              INPUT_FILE_TMP="$INPUT_FILE_TMP $(eval print $(m_expand $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX))"
                           else
                              INPUT_FILE_TMP="$INPUT_FILE_TMP $(eval print $IN_DIR_TMP/$DATA_FILENAME$CNDTL_COMPRESSION_SFX)"
                           fi
                        fi
                     done < $DW_CFG/$ETL_ID.sources.lis
                  fi
               fi
            done
         fi
         ((UOW_ITER_HH=UOW_ITER_HH+1))
      done
      UOW_ITER_DATE=$($DW_BIN/add_days $UOW_ITER_DATE 1)
      UOW_ITER_HH=00
      UOW_ITER_DATEHH=$UOW_ITER_DATE$UOW_ITER_HH
   done

else

   while [[ $BATCH_SEQ_NUM -ge $MIN_BATCH_SEQ_NUM && $BATCH_SEQ_NUM -le $MAX_BATCH_SEQ_NUM ]]
   do
      if [ $EXTRACT_PROCESS_TYPE = 'L' ]
      then
         while read FILE_ID DATA_FILENAME OLD_FILENAME DONE_FILENAME
         do
            if [ $PARALLEL_FILE_LOAD = 1 ]
            then
               if [ $FIRST_FILE = 1 ]
               then
                  eval print $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX $OLD_FILENAME > $INPUT_FILE_FILE
                  FIRST_FILE=0
               else
                  eval print $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX $OLD_FILENAME >> $INPUT_FILE_FILE
               fi
            else
               INPUT_FILE_TMP="$INPUT_FILE_TMP $(eval print $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX)"
            fi
         done < $DW_DAT/extract/$SUBJECT_AREA/$ETL_ID.sources.lis.$BATCH_SEQ_NUM
      elif [ $USE_DISTR_TABLE = 1 ]
      then
         read TABLE_NAME DATA_FILENAME PARAM < $DW_CFG/$ETL_ID.sources.lis

         while read FILE_ID DBC_FILE
         do
            if [ $PARALLEL_FILE_LOAD = 1 ]
            then
               if [ $FIRST_FILE = 1 ]
               then
                    if [ -f $(eval print ${IN_DIR}/.${DATA_FILENAME}.${BATCH_SEQ_NUM}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                    then
                        eval print $(m_expand -native $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX) | tr ' ' '\012' > $EXPANDED_MULTIFILE_FILE
                        FIRST_PASS=1
                        while read EXPANDED_FILENAME
                        do
                            if [ $FIRST_PASS = 1 ]
                            then
                                eval print $EXPANDED_FILENAME $DATA_FILENAME > $INPUT_FILE_FILE
                                FIRST_PASS=0
                            else
                                eval print $EXPANDED_FILENAME $DATA_FILENAME >> $INPUT_FILE_FILE
                            fi
                        done <  $EXPANDED_MULTIFILE_FILE
                        rm $EXPANDED_MULTIFILE_FILE
                    else
                        eval print $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX $DATA_FILENAME > $INPUT_FILE_FILE
                    fi
                  FIRST_FILE=0
               else
                    if [ -f $(eval print ${IN_DIR}/.${DATA_FILENAME}.${BATCH_SEQ_NUM}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                    then
                        eval print $(m_expand -native $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX) | tr ' ' '\012' > $EXPANDED_MULTIFILE_FILE
                        while read EXPANDED_FILENAME
                        do
                            eval print $EXPANDED_FILENAME $DATA_FILENAME >> $INPUT_FILE_FILE
                        done <  $EXPANDED_MULTIFILE_FILE
                        rm $EXPANDED_MULTIFILE_FILE
                    else
                        eval print $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX $DATA_FILENAME >> $INPUT_FILE_FILE
                    fi
               fi
            else
                if [ -f $(eval print ${IN_DIR}/.${DATA_FILENAME}.${BATCH_SEQ_NUM}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                then
                    INPUT_FILE_TMP="$INPUT_FILE_TMP $(eval print $(m_expand $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX))"
                else
                    INPUT_FILE_TMP="$INPUT_FILE_TMP $(eval print $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX)"
                fi
            fi
         done < $DW_CFG/$DISTR_TABLE_LIS_FILE.sources.lis
      else
         while read FILE_ID DBC_FILE PARALLEL_NUM TABLE_NAME DATA_FILENAME PARAM
         do
            if [ $PARALLEL_FILE_LOAD = 1 ]
            then
               if [ $FIRST_FILE = 1 ]
               then
                    if [ -f $(eval print ${IN_DIR}/.${DATA_FILENAME}.${BATCH_SEQ_NUM}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                    then
                        eval print $(m_expand -native $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX) | tr ' ' '\012' > $EXPANDED_MULTIFILE_FILE
                        FIRST_PASS=1
                        while read EXPANDED_FILENAME
                        do
                            if [ $FIRST_PASS = 1 ]
                            then
                                eval print $EXPANDED_FILENAME $DATA_FILENAME > $INPUT_FILE_FILE
                                FIRST_PASS=0
                            else
                                eval print $EXPANDED_FILENAME $DATA_FILENAME >> $INPUT_FILE_FILE
                            fi
                        done <  $EXPANDED_MULTIFILE_FILE
                        rm $EXPANDED_MULTIFILE_FILE
                    else
                        eval print $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX $DATA_FILENAME > $INPUT_FILE_FILE
                    fi
                  FIRST_FILE=0
               else
                    if [ -f $(eval print ${IN_DIR}/.${DATA_FILENAME}.${BATCH_SEQ_NUM}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                    then
                        eval print $(m_expand -native $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX) | tr ' ' '\012' > $EXPANDED_MULTIFILE_FILE
                        while read EXPANDED_FILENAME
                        do
                            eval print $EXPANDED_FILENAME $DATA_FILENAME >> $INPUT_FILE_FILE
                        done <  $EXPANDED_MULTIFILE_FILE
                        rm $EXPANDED_MULTIFILE_FILE
                    else
                        eval print $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX $DATA_FILENAME >> $INPUT_FILE_FILE
                    fi
               fi
            else
                if [ -f $(eval print ${IN_DIR}/.${DATA_FILENAME}.${BATCH_SEQ_NUM}${CNDTL_COMPRESSION_SFX}.mfctl) ]
                then
                    INPUT_FILE_TMP="$INPUT_FILE_TMP $(eval print $(m_expand $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX))"
                else
                    INPUT_FILE_TMP="$INPUT_FILE_TMP $(eval print $IN_DIR/$DATA_FILENAME.$BATCH_SEQ_NUM$CNDTL_COMPRESSION_SFX)"
                fi
            fi
         done < $DW_CFG/$ETL_ID.sources.lis
      fi

      ((BATCH_SEQ_NUM+=1))
   done

fi

print $INPUT_FILE_TMP
)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter INPUT_FILE of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export CNDTL_REFORMAT;CNDTL_REFORMAT=$(grep "^CNDTL_REFORMAT\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print ${VALUE:-0})
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter CNDTL_REFORMAT of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export REFORMAT_TRANS_FILE;REFORMAT_TRANS_FILE="$DW_XFR"'/'"$ETL_ID"'.reformat.xfr'
export OUTPUT_DML;OUTPUT_DML=$(if (($CNDTL_REFORMAT))
then
   print $DW_DML/$ETL_ID.write.dml
else
   print $INPUT_DML
fi)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter OUTPUT_DML of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
export XFORM_REJFILE;XFORM_REJFILE="$DW_SA_TMP"'/'"$TABLE_ID"'.ld.reformat.rej'
export XFORM_ERRFILE;XFORM_ERRFILE="$DW_SA_TMP"'/'"$TABLE_ID"'.ld.reformat.err'
export OUTPUT_FILE;OUTPUT_FILE=$(grep "^HDFS_TGT_FILE\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; eval print $VALUE)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter OUTPUT_FILE of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
HADOOP_CONN=$(grep "^HDFS_TGT_CONN\>" $ETL_CFG_FILE | read PARAM VALUE COMMENT; print $VALUE)
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'parameter HADOOP_CONN of single_hdfs_load', interpretation 'shell'
   exit $mpjret
fi
. ./${_AB_PROXY_DIR}/GDE-Parameters

#+Script Start+  ==================== Edits in this section are preserved.
m_env -v

if [ -z $CNDTL_REFORMAT ]
then
   print "$0: Error: CNDTL_REFORMAT variable not set"
   exit 4
fi

if [ -z $BATCH_SEQ_NUM ]
then
   print "$0: Error: BATCH_SEQ_NUM variable not set"
   exit 4
fi



#+End Script Start+  ====================
# Check that the "mp" program is found correctly on the PATH
case "$_ab_uname" in
  Windows_* )
    _ab_expected_mp=$AB_HOME/bin/mp.exe ;;
  * )
    _ab_expected_mp=$AB_HOME/bin/mp
esac
if [ ! -x "$_ab_expected_mp" ]; then
  print "\n*** ERROR: executable $_ab_expected_mp not found"
  exit 1
fi
_ab_found_mp=$(whence mp)
if [ "$_ab_found_mp" = "" ] || [ "$_ab_found_mp" -ot "$_ab_expected_mp" ] || [ "$_ab_found_mp" -nt "$_ab_expected_mp" ]; then
  if [ "$_ab_found_mp" = "" ]; then
    print "\n*** ERROR: mp not found on PATH"
  else
    case "$_ab_uname" in
      CYGWIN_* )
        _ab_found_mp=`cygpath -m "$_ab_found_mp"` ;;
    esac
    print "\n*** ERROR: Wrong mp found on the PATH: $_ab_found_mp"
    print "           Should be via \$AB_HOME/bin: $_ab_expected_mp"
  fi
  print "\nCheck Setup Script in Host Connections Settings and Script Start in Graph Settings for PATH modifications"
  print "Active PATH=$PATH"
  exit 1
fi
if [ -f "$AB_HOME/bin/ab_catalog_functions.ksh" ]; then . ab_catalog_functions.ksh; fi
mv "${_AB_PROXY_DIR}" "${AB_JOB}"'-single_hdfs_load-ProxyDir'
_AB_PROXY_DIR="${AB_JOB}"'-single_hdfs_load-ProxyDir'
print -r -- 'string('"'"'\n'"'"')' > "${_AB_PROXY_DIR}"'/Load_Reformat-4.dml'

mp job ${AB_JOB}

# Layouts:
mp layout layout1 file:.

# Record Formats (Metadata):
mp metadata metadata1 -file "$INPUT_DML"
mp metadata metadata2 -file "$OUTPUT_DML"
mp metadata metadata3 -file "${_AB_PROXY_DIR}"'/Load_Reformat-4.dml'

export AB_CATALOG;AB_CATALOG=${AB_CATALOG:-"${XX_CATALOG}"}
# Catalog Usage: Creating temporary catalog using lookup files only
m_rmcatalog -catalog GDE-single_hdfs_load-${AB_JOB}.cat > /dev/null 2>&1
m_mkcatalog -catalog GDE-single_hdfs_load-${AB_JOB}.cat
SAVED_CATALOG="${AB_CATALOG}"
export AB_CATALOG;AB_CATALOG='GDE-single_hdfs_load-'"${AB_JOB}"'.cat'
# 
# Initialize condition variables to user-specified conditions
# 
AB_USERCOND_single_hdfs_load=1
AB_IS_LIVE_single_hdfs_load=1
AB_USERCOND_Input_File=1
mpjret=$?
if [ 0 -ne $mpjret ] ; then
   print -- Error evaluating: 'AB_USERCOND_Input_File', interpretation 'shell'
   exit $mpjret
fi
AB_IS_LIVE_Input_File=1
AB_HAS_DATA_Flow_2=1
AB_USERCOND_Load_Reformat="$CNDTL_REFORMAT"
AB_USERCOND_Load_Reformat=$(__AB_COND "${AB_USERCOND_Load_Reformat}")
AB_IS_LIVE_Load_Reformat=1
AB_HAS_DATA_Flow_1=1
AB_HAS_DATA_Flow_13=1
AB_HAS_DATA_Flow_33=1
AB_USERCOND_Write_Hadoop_Files=1
AB_IS_LIVE_Write_Hadoop_Files=1
AB_USERCOND_XForm_Error_File="$CNDTL_REFORMAT"
AB_USERCOND_XForm_Error_File=$(__AB_COND "${AB_USERCOND_XForm_Error_File}")
AB_IS_LIVE_XForm_Error_File=1
AB_USERCOND_XForm_Reject_File="$CNDTL_REFORMAT"
AB_USERCOND_XForm_Reject_File=$(__AB_COND "${AB_USERCOND_XForm_Reject_File}")
AB_IS_LIVE_XForm_Reject_File=1
# 
# Compute condition variables by considering the conditions of neighboring components
# 
done=false
while [ $done = false ] ; do
   done=true
   Temp="${AB_IS_LIVE_Load_Reformat}"
   let AB_IS_LIVE_Load_Reformat="AB_USERCOND_Load_Reformat"
   if [ X"${AB_IS_LIVE_Load_Reformat}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_13}"
   let AB_HAS_DATA_Flow_13="(AB_IS_LIVE_Load_Reformat) && (AB_IS_LIVE_XForm_Reject_File)"
   if [ X"${AB_HAS_DATA_Flow_13}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_HAS_DATA_Flow_33}"
   let AB_HAS_DATA_Flow_33="(AB_IS_LIVE_Load_Reformat) && (AB_IS_LIVE_XForm_Error_File)"
   if [ X"${AB_HAS_DATA_Flow_33}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_XForm_Error_File}"
   let AB_IS_LIVE_XForm_Error_File="(AB_HAS_DATA_Flow_33) && (AB_USERCOND_XForm_Error_File)"
   if [ X"${AB_IS_LIVE_XForm_Error_File}" != X"$Temp" ]; then
      done=false
   fi
   Temp="${AB_IS_LIVE_XForm_Reject_File}"
   let AB_IS_LIVE_XForm_Reject_File="(AB_HAS_DATA_Flow_13) && (AB_USERCOND_XForm_Reject_File)"
   if [ X"${AB_IS_LIVE_XForm_Reject_File}" != X"$Temp" ]; then
      done=false
   fi
done
# 
if [ X"${AB_VERBOSE_CONDITIONS}" != X"" ]; then
   # 
   # echo condition variables
   # 
   print -r -- 'AB_USERCOND_single_hdfs_load=1'
   print -r -- 'AB_IS_LIVE_single_hdfs_load=1'
   print -r -- 'AB_USERCOND_Input_File=1'
   print -r -- 'AB_IS_LIVE_Input_File=1'
   print -r -- 'AB_HAS_DATA_Flow_2=1'
   print -r -- 'AB_USERCOND_Load_Reformat='"${AB_USERCOND_Load_Reformat}"
   print -r -- 'AB_IS_LIVE_Load_Reformat='"${AB_IS_LIVE_Load_Reformat}"
   print -r -- 'AB_HAS_DATA_Flow_1=1'
   print -r -- 'AB_HAS_DATA_Flow_13='"${AB_HAS_DATA_Flow_13}"
   print -r -- 'AB_HAS_DATA_Flow_33='"${AB_HAS_DATA_Flow_33}"
   print -r -- 'AB_USERCOND_Write_Hadoop_Files=1'
   print -r -- 'AB_IS_LIVE_Write_Hadoop_Files=1'
   print -r -- 'AB_USERCOND_XForm_Error_File='"${AB_USERCOND_XForm_Error_File}"
   print -r -- 'AB_IS_LIVE_XForm_Error_File='"${AB_IS_LIVE_XForm_Error_File}"
   print -r -- 'AB_USERCOND_XForm_Reject_File='"${AB_USERCOND_XForm_Reject_File}"
   print -r -- 'AB_IS_LIVE_XForm_Reject_File='"${AB_IS_LIVE_XForm_Reject_File}"
fi

# Files:
mp ifile Input_File $INPUT_FILE
AB_PORT_Input_File_read=Input_File.read
AB_METADATA_Input_File_read=' -metadata metadata1'

# Components in phase 0:
if [ X"${AB_IS_LIVE_Load_Reformat}" != X0 ]; then
   mp reformat-transform Load_Reformat -limit "$XFORM_REJLIMIT" -ramp "$XFORM_REJRAMP" -layout Input_File
   mp add-port Load_Reformat.out.out0 ${REFORMAT_TRANS_FILE:+"$REFORMAT_TRANS_FILE"}
   AB_PORT_Load_Reformat_out_out0=Load_Reformat.out.out0
   AB_METADATA_Load_Reformat_out_out0=' -metadata metadata2'
   AB_PORT_Load_Reformat_reject_out0=Load_Reformat.reject.out0
   AB_METADATA_Load_Reformat_reject_out0=' -metadata metadata1'
   AB_PORT_Load_Reformat_error_out0=Load_Reformat.error.out0
   AB_METADATA_Load_Reformat_error_out0=' -metadata metadata3'
else
   AB_PORT_Load_Reformat_out_out0="${AB_PORT_Input_File_read}"
   AB_METADATA_Load_Reformat_out_out0="${AB_METADATA_Input_File_read}"
   AB_PORT_Load_Reformat_reject_out0="${AB_PORT_Input_File_read}"
   AB_METADATA_Load_Reformat_reject_out0="${AB_METADATA_Input_File_read}"
   AB_PORT_Load_Reformat_error_out0="${AB_PORT_Input_File_read}"
   AB_METADATA_Load_Reformat_error_out0="${AB_METADATA_Input_File_read}"
   :
fi
mp custom Write_Hadoop_Files "$AB_COMPONENTS"'/Datasets/Hadoop/Write_Hadoop_Files.mpc' "$OUTPUT_FILE" "$HADOOP_CONN" -compression none -permissions 644 -HADOOP_HOME "$HADOOP_HOME" -layout Input_File
if [ X"${AB_IS_LIVE_XForm_Error_File}" != X0 ]; then
   mp logger XForm_Error_File "$XFORM_ERRFILE" Start End -layout layout1
else
   :
fi
if [ X"${AB_IS_LIVE_XForm_Reject_File}" != X0 ]; then
   mp logger XForm_Reject_File "$XFORM_REJFILE" Start End -layout layout1
else
   :
fi

# Flows for Entire Graph:
let AB_FLOW_CONDITION="AB_IS_LIVE_Load_Reformat"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp straight-flow Flow_2 "${AB_PORT_Input_File_read}" Load_Reformat.in${AB_METADATA_Input_File_read} -compressed
fi
mp straight-flow Flow_1 "${AB_PORT_Load_Reformat_out_out0}" Write_Hadoop_Files.in${AB_METADATA_Load_Reformat_out_out0}
let AB_FLOW_CONDITION="(AB_IS_LIVE_XForm_Error_File) && (AB_HAS_DATA_Flow_33)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp fan-in-flow Flow_33 "${AB_PORT_Load_Reformat_error_out0}" XForm_Error_File.in${AB_METADATA_Load_Reformat_error_out0}
fi
let AB_FLOW_CONDITION="(AB_IS_LIVE_XForm_Reject_File) && (AB_HAS_DATA_Flow_13)"
if [ X"${AB_FLOW_CONDITION}" != X0 ]; then
   mp fan-in-flow Flow_13 "${AB_PORT_Load_Reformat_reject_out0}" XForm_Reject_File.in${AB_METADATA_Load_Reformat_reject_out0}
fi

if [ X"${AB_VERBOSE_CONDITIONS}" != X"" ]; then
   print -r -- 'Generated graph:'
   mp show
fi
unset AB_COMM_WAIT
export AB_TRACKING_GRAPH_THUMBPRINT;AB_TRACKING_GRAPH_THUMBPRINT=1055070
mp run
mpjret=$?
unset AB_COMM_WAIT
unset AB_TRACKING_GRAPH_THUMBPRINT
mp reset
m_rmcatalog > /dev/null 2>&1
export XX_CATALOG;XX_CATALOG="${SAVED_CATALOG}"
export AB_CATALOG;AB_CATALOG="${SAVED_CATALOG}"

#+Script End+  ==================== Edits in this section are preserved.




























#+End Script End+  ====================

exit $mpjret
